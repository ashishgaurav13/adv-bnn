{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import tqdm\n",
    "import os,sys\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "\n",
    "\n",
    "import re, pickle\n",
    "from torch.utils.data import DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "common.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_type = 'lrt'  # 'bbb' or 'lrt'\n",
    "activation_type = 'softplus'  # 'softplus' or 'relu'\n",
    "priors={\n",
    "    'prior_mu': 0,\n",
    "    'prior_sigma': 0.1,\n",
    "    'posterior_mu_initial': (0, 0.1),  # (mean, std) normal_\n",
    "    'posterior_rho_initial': (-5, 0.1),  # (mean, std) normal_\n",
    "}\n",
    "lr_start = 0.001\n",
    "num_workers = 1\n",
    "valid_size = 0.2\n",
    "batch_size = 256\n",
    "train_ens = 1\n",
    "valid_ens = 1\n",
    "beta_type = 0.1  \n",
    "transform_mnist = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "outputs = 10\n",
    "inputs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='.', train=True, download=True, transform=transform_mnist)\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, \n",
    "                                           sampler=valid_sampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBBLeNet(common.ModuleWrapper):\n",
    "    '''The architecture of LeNet with Bayesian Layers'''\n",
    "\n",
    "    def __init__(self, outputs, inputs, priors, layer_type='lrt', activation_type='softplus'):\n",
    "        super(BBBLeNet, self).__init__()\n",
    "\n",
    "        self.num_classes = outputs\n",
    "        self.layer_type = layer_type\n",
    "        self.priors = priors\n",
    "\n",
    "        if layer_type=='lrt':\n",
    "            BBBLinear = common.layers.BBB_LRT_Linear\n",
    "            BBBConv2d = common.layers.BBB_LRT_Conv2d\n",
    "        elif layer_type=='bbb':\n",
    "            BBBLinear = common.layers.BBB_Linear\n",
    "            BBBConv2d = common.layers.BBB_Conv2d\n",
    "        else:\n",
    "            raise ValueError(\"Undefined layer_type\")\n",
    "        \n",
    "        if activation_type=='softplus':\n",
    "            self.act = nn.Softplus\n",
    "        elif activation_type=='relu':\n",
    "            self.act = nn.ReLU\n",
    "        else:\n",
    "            raise ValueError(\"Only softplus or relu supported\")\n",
    "\n",
    "        self.conv1 = BBBConv2d(inputs, 6, 5, padding=0, bias=True, priors=self.priors)\n",
    "        self.act1 = self.act()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = BBBConv2d(6, 16, 5, padding=0, bias=True, priors=self.priors)\n",
    "        self.act2 = self.act()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = common.layers.FlattenLayer(5 * 5 * 16)\n",
    "        self.fc1 = BBBLinear(5 * 5 * 16, 120, bias=True, priors=self.priors)\n",
    "        self.act3 = self.act()\n",
    "\n",
    "        self.fc2 = BBBLinear(120, 84, bias=True, priors=self.priors)\n",
    "        self.act4 = self.act()\n",
    "\n",
    "        self.fc3 = BBBLinear(84, outputs, bias=True, priors=self.priors)\n",
    "        \n",
    "        \n",
    "class LeNet(nn.Module):\n",
    "\n",
    "    def __init__(self, outputs, inputs, layer_type='lrt', activation_type='softplus'):\n",
    "        '''\n",
    "        Base LeNet model that matches the architecture of BayesianLeNet with randomly \n",
    "        initialized weights\n",
    "        '''\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        # initialization follows the BBBLeNet initialization, changing\n",
    "        # BBBLinear and BBBConv2D layers to nn.Linear and nn.Conv2D\n",
    "        \n",
    "        if activation_type == 'softplus':\n",
    "            self.act = nn.Softplus\n",
    "        elif activation_type == 'relu':\n",
    "            self.act = nn.ReLU\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inputs, 6, 5, padding=0, bias=True)\n",
    "        self.act1 = self.act()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, padding=0, bias=True)\n",
    "        self.act2 = self.act()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(5 * 5 * 16, 120, bias=True)\n",
    "        self.act3 = self.act()\n",
    "        self.fc2 = nn.Linear(120, 84, bias=True)\n",
    "        self.act4 = self.act()\n",
    "        self.fc3 = nn.Linear(84, outputs, bias=True)\n",
    "\n",
    "\n",
    "    def sample(self, bbbnet):\n",
    "        '''\n",
    "        Takes in a BBBLeNet instance and copies the structure into a LeNet model.\n",
    "        Replaces the BBBLinear and BBBConv2D that uses sampling in their forward steps\n",
    "        with regular nn.Linear and nn.Conv2d layers whose weights are initialized by \n",
    "        sampling the BBBLeNet model.\n",
    "        '''    \n",
    "        ### store activation function used by BNN, only relu and softplus  currently supported\n",
    "        self.act1 = bbbnet.act()\n",
    "        self.act2 = bbbnet.act()\n",
    "        self.act3 = bbbnet.act()\n",
    "        self.act4 = bbbnet.act()\n",
    "\n",
    "        ### maxpool\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=bbbnet.pool1.kernel_size, stride=bbbnet.pool1.stride)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=bbbnet.pool2.kernel_size, stride=bbbnet.pool2.stride)\n",
    "        \n",
    "        ### Create Convolution layers\n",
    "        self.conv1 = nn.Conv2d(bbbnet.conv1.in_channels, bbbnet.conv1.out_channels, bbbnet.conv1.kernel_size,\n",
    "                                stride=bbbnet.conv1.stride, padding=bbbnet.conv1.padding, dilation=bbbnet.conv1.dilation,\n",
    "                                groups=bbbnet.conv1.groups)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(bbbnet.conv2.in_channels, bbbnet.conv2.out_channels, bbbnet.conv2.kernel_size,\n",
    "                        stride=bbbnet.conv2.stride, padding=bbbnet.conv2.padding, dilation=bbbnet.conv2.dilation,\n",
    "                        groups=bbbnet.conv2.groups)\n",
    "        \n",
    "        # follows the procedure for sampling in the forward methods of BBBConv and \n",
    "        # BBBLinearforward to create a fixed set of weights to use for the sampled model\n",
    "\n",
    "        conv1_W_mu = bbbnet.conv1.W_mu\n",
    "        conv1_W_rho = bbbnet.conv1.W_rho\n",
    "        conv1_W_eps = torch.empty(conv1_W_mu.size()).normal_(0,1)\n",
    "        conv1_W_sigma = torch.log1p(torch.exp(conv1_W_rho))\n",
    "        conv1_weight = conv1_W_mu + conv1_W_eps * conv1_W_sigma\n",
    "        if bbbnet.conv1.use_bias:\n",
    "            conv1_bias_mu = bbbnet.conv1.bias_mu\n",
    "            conv1_bias_rho = bbbnet.conv1.bias_rho\n",
    "            conv1_bias_eps = torch.empty(conv1_bias_mu.size()).normal_(0,1)\n",
    "            conv1_bias_sigma = torch.log1p(torch.exp(conv1_bias_rho))\n",
    "            conv1_bias = conv1_bias_mu + conv1_bias_eps * conv1_bias_sigma\n",
    "        else:\n",
    "            conv1_bias = None\n",
    "        self.conv1.weight.data = conv1_weight.data\n",
    "        self.conv1.bias.data = conv1_bias.data\n",
    "\n",
    "\n",
    "        conv2_W_mu = bbbnet.conv2.W_mu\n",
    "        conv2_W_rho = bbbnet.conv2.W_rho\n",
    "        conv2_W_eps = torch.empty(conv2_W_mu.size()).normal_(0,1)\n",
    "        conv2_W_sigma = torch.log1p(torch.exp(conv2_W_rho))\n",
    "        conv2_weight = conv2_W_mu + conv2_W_eps * conv2_W_sigma\n",
    "        if bbbnet.conv2.use_bias:\n",
    "            conv2_bias_mu = bbbnet.conv2.bias_mu\n",
    "            conv2_bias_rho = bbbnet.conv2.bias_rho\n",
    "            conv2_bias_eps = torch.empty(conv2_bias_mu.size()).normal_(0,1)\n",
    "            conv2_bias_sigma = torch.log1p(torch.exp(conv2_bias_rho))\n",
    "            conv2_bias = conv2_bias_mu + conv2_bias_eps * conv2_bias_sigma\n",
    "        else:\n",
    "            conv2_bias = None\n",
    "        self.conv2.weight.data = conv2_weight.data\n",
    "        self.conv2.bias.data = conv2_bias.data\n",
    "        \n",
    "        ### Create Linear Layers\n",
    "        self.fc1 = nn.Linear(bbbnet.fc1.in_features, bbbnet.fc1.out_features, bbbnet.fc1.use_bias)\n",
    "        self.fc2 = nn.Linear(bbbnet.fc2.in_features, bbbnet.fc2.out_features, bbbnet.fc2.use_bias)\n",
    "        self.fc3 = nn.Linear(bbbnet.fc3.in_features, bbbnet.fc3.out_features, bbbnet.fc3.use_bias)\n",
    "\n",
    "        fc1_W_mu = bbbnet.fc1.W_mu\n",
    "        fc1_W_rho = bbbnet.fc1.W_rho\n",
    "        fc1_W_eps = torch.empty(fc1_W_mu.size()).normal_(0,1)\n",
    "        fc1_W_sigma = torch.log1p(torch.exp(fc1_W_rho))\n",
    "        fc1_weight = fc1_W_mu + fc1_W_eps * fc1_W_sigma\n",
    "        if bbbnet.fc1.use_bias:\n",
    "            fc1_bias_mu = bbbnet.fc1.bias_mu\n",
    "            fc1_bias_rho = bbbnet.fc1.bias_rho\n",
    "            fc1_bias_eps = torch.empty(fc1_bias_mu.size()).normal_(0,1)\n",
    "            fc1_bias_sigma = torch.log1p(torch.exp(fc1_bias_rho))\n",
    "            fc1_bias = fc1_bias_mu + fc1_bias_eps * fc1_bias_sigma\n",
    "        else:\n",
    "            fc1_bias = None\n",
    "        self.fc1.weight.data = fc1_weight.data\n",
    "        self.fc1.bias.data = fc1_bias.data\n",
    "\n",
    "        fc2_W_mu = bbbnet.fc2.W_mu\n",
    "        fc2_W_rho = bbbnet.fc2.W_rho\n",
    "        fc2_W_eps = torch.empty(fc2_W_mu.size()).normal_(0,1)\n",
    "        fc2_W_sigma = torch.log1p(torch.exp(fc2_W_rho))\n",
    "        fc2_weight = fc2_W_mu + fc2_W_eps * fc2_W_sigma\n",
    "        if bbbnet.fc2.use_bias:\n",
    "            fc2_bias_mu = bbbnet.fc2.bias_mu\n",
    "            fc2_bias_rho = bbbnet.fc2.bias_rho\n",
    "            fc2_bias_eps = torch.empty(fc2_bias_mu.size()).normal_(0,1)\n",
    "            fc2_bias_sigma = torch.log1p(torch.exp(fc2_bias_rho))\n",
    "            fc2_bias = fc2_bias_mu + fc2_bias_eps * fc2_bias_sigma\n",
    "        else:\n",
    "            fc2_bias = None\n",
    "        self.fc2.weight.data = fc2_weight.data\n",
    "        self.fc2.bias.data = fc2_bias.data\n",
    "\n",
    "        fc3_W_mu = bbbnet.fc3.W_mu\n",
    "        fc3_W_rho = bbbnet.fc3.W_rho\n",
    "        fc3_W_eps = torch.empty(fc3_W_mu.size()).normal_(0,1)\n",
    "        fc3_W_sigma = torch.log1p(torch.exp(fc3_W_rho))\n",
    "        fc3_weight = fc3_W_mu + fc3_W_eps * fc3_W_sigma\n",
    "        if bbbnet.fc3.use_bias:\n",
    "            fc3_bias_mu = bbbnet.fc3.bias_mu\n",
    "            fc3_bias_rho = bbbnet.fc3.bias_rho\n",
    "            fc3_bias_eps = torch.empty(fc3_bias_mu.size()).normal_(0,1)\n",
    "            fc3_bias_sigma = torch.log1p(torch.exp(fc3_bias_rho))\n",
    "            fc3_bias = fc3_bias_mu + fc3_bias_eps * fc3_bias_sigma\n",
    "        else:\n",
    "            fc3_bias = None\n",
    "        self.fc3.weight.data = fc3_weight.data\n",
    "        self.fc3.bias.data = fc3_bias.data\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Forward method follow the order of BayesianLeNet\n",
    "        '''\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(-1, 5 * 5 * 16)\n",
    "        x = self.fc1(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BBBLeNet(outputs, inputs, priors, layer_type, activation_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(K = 100, modelname=\"models/model-cnn.pt\"):\n",
    "    # Load the models\n",
    "    sampled_models = [LeNet(outputs, inputs, layer_type, activation_type) for i in range(K)]\n",
    "    for net, state_dict in zip(sampled_models, torch.load(modelname,map_location=torch.device('cpu') )):\n",
    "        net.load_state_dict(state_dict)\n",
    "    print(\"Loaded %d sample models\" % K)\n",
    "    return sampled_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Test Accuracy (eps=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_back = transforms.Compose([transforms.Resize((28,28))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_itcm_0.05/\") if \"test_images_med\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_itcm_0.05/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "# images  = images[:,0,:,:]\n",
    "\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_test_dataset.data    = None\n",
    "adv_test_dataset.targets = None\n",
    "\n",
    "adv_test_dataset.data    = images\n",
    "adv_test_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_test_loader = torch.utils.data.DataLoader(adv_test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_itcm_0.05/\") if \"test_images_champ\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_itcm_0.05/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "# images  = images[:,0,:,:]\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_champ_test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_champ_test_dataset.data    = None\n",
    "adv_champ_test_dataset.targets = None\n",
    "\n",
    "adv_champ_test_dataset.data    = images\n",
    "adv_champ_test_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_champ_test_loader = torch.utils.data.DataLoader(adv_champ_test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_itcm_0.05/\") if \"test_images_mean\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_itcm_0.05/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "# images  = images[:,0,:,:]\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_mean_test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_mean_test_dataset.data    = None\n",
    "adv_mean_test_dataset.targets = None\n",
    "\n",
    "adv_mean_test_dataset.data    = images\n",
    "adv_mean_test_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_mean_test_loader = torch.utils.data.DataLoader(adv_mean_test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_itcm_0.18/\") if \"test_images_med\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_itcm_0.18/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "# images  = images[:,0,:,:]\n",
    "\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_test_18_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_test_18_dataset.data    = None\n",
    "adv_test_18_dataset.targets = None\n",
    "\n",
    "adv_test_18_dataset.data    = images\n",
    "adv_test_18_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_test_18_loader = torch.utils.data.DataLoader(adv_test_18_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_itcm_0.18/\") if \"test_images_champ\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_itcm_0.18/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "# images  = images[:,0,:,:]\n",
    "\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_champ_test_18_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_champ_test_18_dataset.data    = None\n",
    "adv_champ_test_18_dataset.targets = None\n",
    "\n",
    "adv_champ_test_18_dataset.data    = images\n",
    "adv_champ_test_18_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_champ_test_18_loader = torch.utils.data.DataLoader(adv_champ_test_18_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_itcm_0.18/\") if \"test_images_mean\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_itcm_0.18/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "# images  = images[:,0,:,:]\n",
    "\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_mean_test_18_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_mean_test_18_dataset.data    = None\n",
    "adv_mean_test_18_dataset.targets = None\n",
    "\n",
    "adv_mean_test_18_dataset.data    = images\n",
    "adv_mean_test_18_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_mean_test_18_loader = torch.utils.data.DataLoader(adv_mean_test_18_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_itcm_0.5/\") if \"test_images_med\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_itcm_0.5/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "# images  = images[:,0,:,:]\n",
    "\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_test_50_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_test_50_dataset.data    = None\n",
    "adv_test_50_dataset.targets = None\n",
    "\n",
    "adv_test_50_dataset.data    = images\n",
    "adv_test_50_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_test_50_loader = torch.utils.data.DataLoader(adv_test_50_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_itcm_0.5/\") if \"test_images_champ\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_itcm_0.5/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "# images  = images[:,0,:,:]\n",
    "\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_champ_test_50_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_champ_test_50_dataset.data    = None\n",
    "adv_champ_test_50_dataset.targets = None\n",
    "\n",
    "adv_champ_test_50_dataset.data    = images\n",
    "adv_champ_test_50_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_champ_test_50_loader = torch.utils.data.DataLoader(adv_champ_test_50_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 32, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, loader):\n",
    "    total_correct = 0\n",
    "    for data in loader:\n",
    "        images, labels = data\n",
    "        # images = images.view(-1, 28*28)\n",
    "        y    = model(images)\n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        total_correct += torch.sum(pred==labels).item()\n",
    "    return total_correct / len(loader.dataset.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdvBNN vs BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n"
     ]
    }
   ],
   "source": [
    "sampled_adv_models_50       = load_models(K = 50,modelname=\"models/lenet-mnist-adv-med-0.5.pt\")\n",
    "sampled_adv_models_50_champ = load_models(K = 50,modelname=\"models/lenet-mnist-adv-champ-0.5.pt\")\n",
    "# sampled_adv_models_50_mean  = load_models(K = 50,modelname=\"models/model-cnn-adv-mean0.50.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n"
     ]
    }
   ],
   "source": [
    "sampled_adv_models_18       = load_models(K = 50,modelname=\"models/lenet-mnist-adv-med-0.18.pt\")\n",
    "sampled_adv_models_18_champ = load_models(K = 50,modelname=\"models/lenet-mnist-adv-champ-0.18.pt\")\n",
    "# sampled_adv_models_18_mean  = load_models(K = 50,modelname=\"models/model-cnn-adv-mean0.18.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n"
     ]
    }
   ],
   "source": [
    "sampled_adv_models_05       = load_models(K = 50,modelname=\"models/lenet-mnist-adv-med-0.05.pt\")\n",
    "sampled_adv_models_05_champ = load_models(K = 50,modelname=\"models/lenet-mnist-adv-champ-0.05.pt\")\n",
    "# sampled_adv_models_05_mean  = load_models(K = 50,modelname=\"models/model-cnn-adv-mean0.05.pt\")\n",
    "\n",
    "sampled_models        = load_models(K = 50,modelname=\"models/model-cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = torch.load(\"models/CNN.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9827"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7455830388692579"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, adv_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7425930959499865"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, adv_champ_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7633867898885567"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, adv_mean_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8604706160577037"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, adv_test_18_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8035946553151235"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, adv_champ_test_18_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4835397835063051"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, adv_test_50_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2807722352416025"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, adv_champ_test_50_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.05) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9891\n",
      "mean:  0.985804 , sd:  0.002\n",
      "min:   0.9804\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_05]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.05) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.989\n",
      "mean:  0.985404 , sd:  0.002\n",
      "min:   0.9804\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_05_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=18) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.9885\n",
      "mean:  0.9853299999999997 , sd:  0.002\n",
      "min:  0.979\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_18]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=18) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.9887\n",
      "mean:  0.985048 , sd:  0.002\n",
      "min:  0.9807\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_18_champ]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=50) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.9876\n",
      "mean:  0.984232 , sd:  0.0017\n",
      "min:  0.98\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_50]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=50) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.9869\n",
      "mean:  0.984666 , sd:  0.0017\n",
      "min:  0.9793\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_50_champ]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.9824\n",
      "mean:  0.975064 , sd:  0.0083\n",
      "min:  0.938\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.05) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.8594726827942376\n",
      "mean:  0.8438570263658604 , sd:  0.0083\n",
      "min:   0.8240010872519706\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_adv_models_05]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.05) vs AdvTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.856754552867627\n",
      "mean:  0.8432128295732536 , sd:  0.0074\n",
      "min:   0.8253601522152759\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in sampled_adv_models_05_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.18) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.8547159554226692\n",
      "mean:  0.8410138624626258 , sd:  0.0083\n",
      "min:   0.820195705354716\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_adv_models_18]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.18) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.856482739874966\n",
      "mean:  0.8421473226420223 , sd:  0.0084\n",
      "min:   0.8206034248437075\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_adv_models_18_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.50) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.8151671649904866\n",
      "mean:  0.7963468333786355 , sd:  0.0118\n",
      "min:   0.7628431639032346\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_adv_models_50]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.50) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.8101386246262572\n",
      "mean:  0.7832780646914922 , sd:  0.0149\n",
      "min:   0.7519706441967926\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_adv_models_50_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN vs. Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.7606686599619462\n",
      "mean:  0.6968578418048382 , sd:  0.0376\n",
      "min:   0.5863006251698831\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_models]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.7590377820059799\n",
      "mean:  0.6969611307420496 , sd:  0.0384\n",
      "min:   0.5830388692579506\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_champ_test_loader) for model in  sampled_models]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9065862599030389\n",
      "mean:  0.8366371053565093 , sd:  0.0414\n",
      "min:   0.7172756296559063\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_18_loader) for model in  sampled_models]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Test (eps=0.18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5607749192792417"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, adv_test_18_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.05) vs Adv Test (eps=0.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9495092822513894\n",
      "mean:  0.92960151353908 , sd:  0.0147\n",
      "min:   0.8823459855740806\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_18_loader) for model in  sampled_adv_models_05]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.05) vs AdvTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9509282251389382\n",
      "mean:  0.9333735367151473 , sd:  0.0142\n",
      "min:   0.8947617358401324\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_18_loader) for model in sampled_adv_models_05_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.18) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.969019746955185\n",
      "mean:  0.9635544519333098 , sd:  0.0035\n",
      "min:   0.9498640179732766\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_18_loader) for model in  sampled_adv_models_18]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.50) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9606243348705215\n",
      "mean:  0.9483883173702259 , sd:  0.0066\n",
      "min:   0.9316542509164006\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_18_loader) for model in  sampled_adv_models_50_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.50) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9620432777580702\n",
      "mean:  0.9547853848882581 , sd:  0.0048\n",
      "min:   0.9413503606479839\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_18_loader) for model in  sampled_adv_models_50]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.18) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9705569350833629\n",
      "mean:  0.9659571952228923 , sd:  0.0023\n",
      "min:   0.9588506562610855\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_18_loader) for model in  sampled_adv_models_18_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN vs. Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9065862599030389\n",
      "mean:  0.8366371053565093 , sd:  0.0414\n",
      "min:   0.7172756296559063\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_18_loader) for model in  sampled_models]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accs = [evaluate_accuracy(model, adv_champ_test_18_loader) for model in  sampled_models]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Test (eps=0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_accuracy(cnn_model, adv_test_50_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.05) vs Adv Test (eps=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.5594241714094409\n",
      "mean:  0.44562214038611764 , sd:  0.046\n",
      "min:   0.33433768552616894\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_50_loader) for model in  sampled_adv_models_05]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.05) vs Adv Test (Champ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accs = [evaluate_accuracy(model, adv_champ_test_loader) for model in  sampled_adv_models_05]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.05) vs AdvTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.5566343042071198\n",
      "mean:  0.437580627162147 , sd:  0.0511\n",
      "min:   0.3020868206673362\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_50_loader) for model in sampled_adv_models_05_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.18) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.7084030800133914\n",
      "mean:  0.6112554402410446 , sd:  0.0507\n",
      "min:   0.5181341368150876\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_50_loader) for model in  sampled_adv_models_18]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.18) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.7733511884834282\n",
      "mean:  0.6913223970539002 , sd:  0.0426\n",
      "min:   0.5975895547371946\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_50_loader) for model in  sampled_adv_models_18_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.50) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9631737529293606\n",
      "mean:  0.9531123758509092 , sd:  0.0076\n",
      "min:   0.9235576386564\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_50_loader) for model in  sampled_adv_models_50]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.50) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9569244503961611\n",
      "mean:  0.9462359111706283 , sd:  0.007\n",
      "min:   0.9192054458207789\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_50_loader) for model in  sampled_adv_models_50_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN vs. Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.3740653944872224\n",
      "mean:  0.26301082468474496 , sd:  0.0471\n",
      "min:   0.1648253543131347\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_50_loader) for model in  sampled_models]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
