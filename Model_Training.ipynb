{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyro'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ec9427694030>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyro'"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import tqdm\n",
    "import os, pickle, re, copy\n",
    "import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "common.set_seed(156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "    def __init__(self, ni, nh, no):\n",
    "        super(NN, self).__init__()\n",
    "        self.A = torch.nn.Linear(ni, nh)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.B = torch.nn.Linear(nh, no)\n",
    "    def forward(self, x):\n",
    "        # Two layer neural network\n",
    "        x = self.B(self.relu(self.A(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NN(28*28, 1024, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, y):\n",
    "    # Put priors on weights and biases \n",
    "    priors = {\n",
    "        \"A.weight\": pyro.distributions.Normal(\n",
    "            loc=torch.zeros_like(net.A.weight), \n",
    "            scale=torch.ones_like(net.A.weight),\n",
    "        ).independent(2),\n",
    "        \"A.bias\": pyro.distributions.Normal(\n",
    "            loc=torch.zeros_like(net.A.bias), \n",
    "            scale=torch.ones_like(net.A.bias),\n",
    "        ).independent(1),\n",
    "        \"B.weight\": pyro.distributions.Normal(\n",
    "            loc=torch.zeros_like(net.B.weight), \n",
    "            scale=torch.ones_like(net.B.weight),\n",
    "        ).independent(2),\n",
    "        \"B.bias\": pyro.distributions.Normal(\n",
    "            loc=torch.zeros_like(net.B.bias), \n",
    "            scale=torch.ones_like(net.B.bias),\n",
    "        ).independent(1),\n",
    "    }\n",
    "    # Create a NN module using the priors\n",
    "    lmodule = pyro.random_module(\"module\", net, priors)\n",
    "    regressor = lmodule()\n",
    "    # Do a forward pass on the NN module, i.e. yhat=f(x) and condition on yhat=y\n",
    "    lhat = torch.nn.LogSoftmax(dim=1)(regressor(x))\n",
    "    pyro.sample(\"obs\", pyro.distributions.Categorical(logits=lhat).independent(1), obs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "softplus = torch.nn.Softplus()\n",
    "def guide(x, y):\n",
    "    # Create parameters for variational distribution priors\n",
    "    Aw_mu = pyro.param(\"Aw_mu\", torch.randn_like(net.A.weight))\n",
    "    Aw_sigma = softplus(pyro.param(\"Aw_sigma\", torch.randn_like(net.A.weight)))\n",
    "    Ab_mu = pyro.param(\"Ab_mu\", torch.randn_like(net.A.bias))\n",
    "    Ab_sigma = softplus(pyro.param(\"Ab_sigma\", torch.randn_like(net.A.bias)))\n",
    "    Bw_mu = pyro.param(\"Bw_mu\", torch.randn_like(net.B.weight))\n",
    "    Bw_sigma = softplus(pyro.param(\"Bw_sigma\", torch.randn_like(net.B.weight)))\n",
    "    Bb_mu = pyro.param(\"Bb_mu\", torch.randn_like(net.B.bias))\n",
    "    Bb_sigma = softplus(pyro.param(\"Bb_sigma\", torch.randn_like(net.B.bias)))\n",
    "    # Create random variables similarly to model\n",
    "    priors = {\n",
    "        \"A.weight\": pyro.distributions.Normal(loc=Aw_mu, scale=Aw_sigma).independent(2),\n",
    "        \"A.bias\": pyro.distributions.Normal(loc=Ab_mu, scale=Ab_sigma).independent(1),\n",
    "        \"B.weight\": pyro.distributions.Normal(loc=Bw_mu, scale=Bw_sigma).independent(2),\n",
    "        \"B.bias\": pyro.distributions.Normal(loc=Bb_mu, scale=Bb_sigma).independent(1),\n",
    "    }\n",
    "    # Return NN module from these random variables\n",
    "    lmodule = pyro.random_module(\"module\", net, priors)\n",
    "    return lmodule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do stochastic variational inference to find q(w) closest to p(w|D)\n",
    "svi = pyro.infer.SVI(\n",
    "    model, guide, pyro.optim.Adam({'lr': 0.01}), pyro.infer.Trace_ELBO(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_models(epochs = 10, K = 100, modelname = \"model.pt\"):\n",
    "    if os.path.exists(modelname):\n",
    "        print(\"File exists\")\n",
    "        return\n",
    "    # Train with SVI\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0.\n",
    "        for data in train_loader:\n",
    "            images, labels = data\n",
    "            images = images.view(-1, 28*28)\n",
    "            loss += svi.step(images, labels)\n",
    "        loss /= len(train_loader.dataset)\n",
    "        print(\"Epoch %g: Loss = %g\" % (epoch, loss))\n",
    "    # Sample k models from the posterior\n",
    "    sampled_models = [guide(None, None) for i in range(K)]\n",
    "    # Save the models\n",
    "    nn_dicts = []\n",
    "    for i in range(len(sampled_models)):\n",
    "        nn_dicts += [sampled_models[i].state_dict()]\n",
    "    torch.save(nn_dicts, modelname)\n",
    "    print(\"Saved %d models\" % K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(K = 100, model_name=\"model.pt\"):\n",
    "    # Load the models\n",
    "    sampled_models = [NN(28*28, 1024, 10) for i in range(K)]\n",
    "    for net, state_dict in zip(sampled_models, torch.load(\"models/%s\" % model_name)):\n",
    "        net.load_state_dict(state_dict)\n",
    "    print(\"Loaded %d sample models\" % K)\n",
    "    return sampled_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_and_save_models(epochs = 10, K = 100, modelname = \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training BNN with Adversarial Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "train_dataset = torchvision.datasets.MNIST('.', train=True, download=True,\n",
    "                       transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs    = [d for d in os.listdir(\"mnist_adv/\") if d.startswith(\"train_images_med\")]\n",
    "dir_ord = sorted([int(re.findall(\"[0-9]+\",d)[0]) for d in dirs])\n",
    "dirs    = sorted(dirs, key=lambda x: dir_ord.index(int(re.findall(\"[0-9]+\",x)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images  = []\n",
    "targets = []\n",
    "for d in dirs[:100]:\n",
    "    with open(\"mnist_adv/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "targets = torch.hstack(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.data    = torch.vstack([train_dataset.data, images])\n",
    "train_dataset.targets = torch.hstack([train_dataset.targets, targets])\n",
    "\n",
    "train, val = random_split(train_dataset,[50000+images.shape[0],10000], generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# Train data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True)\n",
    "val_loader   = torch.utils.data.DataLoader(val  , batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 9 # try 1\n",
    "plt.figure()\n",
    "plt.imshow(img[0][ind,0,:,:], cmap='gray')\n",
    "plt.title(\"Class: %s\" % img[1][ind].item())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdvBNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 224.907: Val_Loss = 155.048\n",
      "New minimum loss was reached\n",
      "Saved 100 models\n",
      "Epoch 1: Loss = 126.228: Val_Loss = 110.348\n",
      "New minimum loss was reached\n",
      "Saved 100 models\n",
      "Epoch 2: Loss = 102.098: Val_Loss = 96.711\n",
      "New minimum loss was reached\n",
      "Saved 100 models\n",
      "Epoch 3: Loss = 94.6596: Val_Loss = 92.7928\n",
      "New minimum loss was reached\n",
      "Saved 100 models\n",
      "Epoch 4: Loss = 90.8076: Val_Loss = 89.341\n",
      "New minimum loss was reached\n",
      "Saved 100 models\n",
      "Epoch 5: Loss = 89.4689: Val_Loss = 89.0899\n",
      "New minimum loss was reached\n",
      "Saved 100 models\n",
      "Epoch 6: Loss = 89.256: Val_Loss = 87.3815\n",
      "New minimum loss was reached\n",
      "Saved 100 models\n",
      "Epoch 7: Loss = 89.206: Val_Loss = 89.2695\n",
      "Epoch 8: Loss = 88.9558: Val_Loss = 88.0049\n",
      "Epoch 9: Loss = 89.5115: Val_Loss = 88.6798\n",
      "Epoch 10: Loss = 89.0705: Val_Loss = 89.7829\n",
      "Epoch 11: Loss = 89.3799: Val_Loss = 90.5028\n",
      "Epoch 12: Loss = 89.4893: Val_Loss = 90.1578\n",
      "Epoch 13: Loss = 89.1492: Val_Loss = 88.9892\n",
      "Epoch 14: Loss = 88.8912: Val_Loss = 88.2839\n",
      "Epoch 15: Loss = 88.9379: Val_Loss = 88.1863\n",
      "Epoch 16: Loss = 88.2082: Val_Loss = 88.8862\n",
      "Epoch 17: Loss = 88.1866: Val_Loss = 89.5607\n",
      "Epoch 18: Loss = 88.3216: Val_Loss = 89.6839\n",
      "Epoch 19: Loss = 88.0742: Val_Loss = 88.4927\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "K = 100\n",
    "modelname = \"AdvBNN\"\n",
    "# Train with SVI\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    loss = 0.\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images = images.view(-1, 28*28)\n",
    "        loss  += svi.step(images, labels)\n",
    "    loss /= len(train_loader.dataset)\n",
    "    # Evaluation\n",
    "    val_loss = 0.\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        images = images.view(-1, 28*28)\n",
    "        val_loss += svi.evaluate_loss(images, labels)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    print(\"Epoch %g: Loss = %g: Val_Loss = %g\" % (epoch, loss,val_loss))\n",
    "    if val_loss == min(val_losses):\n",
    "        print(\"New minimum loss was reached\")\n",
    "        # Sample k models from the posterior\n",
    "        sampled_models = [guide(None, None) for i in range(K)]\n",
    "        # Save the models\n",
    "        nn_dicts = []\n",
    "        for i in range(len(sampled_models)):\n",
    "            nn_dicts += [sampled_models[i].state_dict()]\n",
    "        torch.save(nn_dicts, \"models/%s_%s.pt\" % (modelname, val_loss))\n",
    "        print(\"Saved %d models\" % K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdvFFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "epochs = 15\n",
    "K      = 100\n",
    "modelname = \"AdvFFNN\"\n",
    "lr     = 0.01\n",
    "\n",
    "# Train with BinaryCrossEntropy\n",
    "val_losses = []\n",
    "model = NN(28*28, 1024, 10)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fcn  = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images = images.view(-1, 28*28)\n",
    "        y = model(images)\n",
    "        loss = loss_fcn(y, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        total_loss += loss.item()\n",
    "    total_loss /= len(train_loader.dataset)\n",
    "    # Evaluation\n",
    "    val_loss = 0.\n",
    "    model.eval()\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        y    = model(images)\n",
    "        loss = loss_fcn(y, labels)\n",
    "        val_loss += loss.item()\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    print(\"Epoch %g: Loss = %g: Val_Loss = %g\" % (epoch, total_loss,val_loss))\n",
    "    if val_loss == min(val_losses):\n",
    "        print(\"New minimum loss was reached\")\n",
    "        # Sample k models from the posterior\n",
    "        sampled_models = [guide(None, None) for i in range(K)]\n",
    "        # Save the models\n",
    "        nn_dicts = []\n",
    "        for i in range(len(sampled_models)):\n",
    "            nn_dicts += [sampled_models[i].state_dict()]\n",
    "        torch.save(nn_dicts, \"models/%s_ep%s_loss%s.pt\" % (modelname, val_loss))\n",
    "        print(\"Saved %d models\" % K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.00185364\n",
      "Epoch 1: Loss = 0.000930323\n",
      "Epoch 2: Loss = 0.00073556\n",
      "Epoch 3: Loss = 0.000583742\n",
      "Epoch 4: Loss = 0.00055748\n",
      "Epoch 5: Loss = 0.000542039\n",
      "Epoch 6: Loss = 0.000428012\n",
      "Epoch 7: Loss = 0.000463505\n",
      "Epoch 8: Loss = 0.000365677\n",
      "Epoch 9: Loss = 0.000414745\n",
      "Saved the model\n"
     ]
    }
   ],
   "source": [
    "# HyperParameters\n",
    "epochs = 10\n",
    "K      = 100\n",
    "modelname = \"AdvFFNN\"\n",
    "lr     = 0.01\n",
    "\n",
    "# Train with BinaryCrossEntropy\n",
    "val_losses = []\n",
    "model = NN(28*28, 1024, 10)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fcn  = torch.nn.CrossEntropyLoss(reduce=\"mean\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images = images.view(-1, 28*28)\n",
    "        y = model(images)\n",
    "        loss = loss_fcn(y, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        total_loss += loss.item()\n",
    "    total_loss /= len(train_loader.dataset)\n",
    "    print(\"Epoch %g: Loss = %g\" % (epoch, total_loss))\n",
    "\n",
    "torch.save(model, \"models/%s.pt\" % modelname)\n",
    "print(\"Saved the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Adversarial Test Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Adv Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv/\") if \"test_images_med\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv/\"+d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "targets = torch.hstack(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=torchvision.transforms.ToTensor())\n",
    "test_dataset.data    = None\n",
    "test_dataset.targets = None\n",
    "\n",
    "test_dataset.data    = images\n",
    "test_dataset.targets = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12288, 28, 28])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.dataset.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "test_loss = 0.\n",
    "for data in test_loader:\n",
    "    images, labels = data\n",
    "    images = images.view(-1, 28*28)\n",
    "    test_loss += svi.evaluate_loss(images, labels)\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(\"Test_Loss = %g\" % (test_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fooling_rate(sampled_models, adv_image, target):\n",
    "    fool = 0\n",
    "    for k in range(len(sampled_models)):\n",
    "        # Forward pass again on adv. example\n",
    "        pred = forward_pass(sampled_models[k], adv_image)\n",
    "        # If we change the class, we fool the model\n",
    "        fool += int(target != pred)\n",
    "    return fool/len(sampled_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(model, images, loss_target = None):\n",
    "    output = model(images)\n",
    "    output = torch.nn.LogSoftmax(dim=-1)(output)\n",
    "    which_class = torch.argmax(output).item()\n",
    "    if loss_target:\n",
    "        loss, target = loss_target\n",
    "        loss(output, target).backward()\n",
    "    return which_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data loader with batch_size 1\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25 sample models\n",
      "Loaded 25 sample models\n"
     ]
    }
   ],
   "source": [
    "sampled_models_BNN = load_models(K = 25,model_name=\"model.pt\")\n",
    "sampled_models_AdvBNN = load_models(K = 25,model_name=\"AdvBNN_87.3814625.pt\")\n",
    "AdvFFNN = torch.load(\"models/AdvFFNN.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 1999 / 12288\n",
      "AdvBNN: 0.5108154077038518, BNN 0.7912156078039062, AdvBNN_med: 0.5102551275637819, AdvFFNN 0.014007003501750876\n",
      "\n",
      " Processing 3999 / 12288\n",
      "AdvBNN: 0.5129082270567661, BNN 0.7876869217304502, AdvBNN_med: 0.5133783445861465, AdvFFNN 0.012253063265816454\n",
      "\n",
      " Processing 5999 / 12288\n",
      "AdvBNN: 0.5137189531588604, BNN 0.7879513252208977, AdvBNN_med: 0.5132522087014503, AdvFFNN 0.012668778129688281\n",
      "\n",
      " Processing 7999 / 12288\n",
      "AdvBNN: 0.5121990248781089, BNN 0.7869583697962678, AdvBNN_med: 0.5114389298662333, AdvFFNN 0.01362670333791724\n",
      "\n",
      " Processing 9999 / 12288\n",
      "AdvBNN: 0.5104230423042277, BNN 0.7858065806581176, AdvBNN_med: 0.5076507650765076, AdvFFNN 0.015201520152015202\n",
      "\n",
      " Processing 11999 / 12288\n",
      "AdvBNN: 0.5104892074339492, BNN 0.7862721893491296, AdvBNN_med: 0.5067088924077007, AdvFFNN 0.015417951495957996\n",
      "\n",
      " Processing 12287 / 12288\n",
      "AdvBNN: 0.5105851713192773, BNN 0.7865581508911961, AdvBNN_med: 0.5071213477659314, AdvFFNN 0.015137950679580044\n",
      "\n",
      " Processing 12288 / 12288"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "fool_rates_BNN         = []\n",
    "fool_rates_AdvBNN      = []\n",
    "fool_rates_AdvBNN_med  = []\n",
    "fool_rates_AdvFFNN     = []\n",
    "counter = 1\n",
    "for images, labels in test_loader:\n",
    "    print(\"\\r Processing %s / %s\" % (counter,len(test_loader.dataset.targets)), end=\"\")\n",
    "    images = images.view(-1, 28*28)\n",
    "    fool_rates_BNN.append(fooling_rate(sampled_models_BNN,images,labels))\n",
    "    fool_rates_AdvBNN.append(fooling_rate(sampled_models_AdvBNN,images,labels))\n",
    "    fool_rates_AdvBNN_med.append( 1 if fooling_rate(sampled_models_AdvBNN,images,labels) > 0.5 else 0 )\n",
    "    fool_rates_AdvFFNN.append(fooling_rate([AdvFFNN],images,labels))\n",
    "    if counter % 2000 == 0 or counter == len(test_loader.dataset.targets):\n",
    "        bnn_rate      = sum(fool_rates_BNN) / len(fool_rates_BNN)\n",
    "        advbnn_rate   = sum(fool_rates_AdvBNN) / len(fool_rates_AdvBNN)\n",
    "        advbnn_rate_m = sum(fool_rates_AdvBNN_med) / len(fool_rates_AdvBNN_med)\n",
    "        advffnn_rate  = sum(fool_rates_AdvFFNN) / len(fool_rates_AdvFFNN)\n",
    "        print(\"\\nAdvBNN: %s, BNN %s, AdvBNN_med: %s, AdvFFNN %s\\n\" % (advbnn_rate, bnn_rate,advbnn_rate_m, advffnn_rate))\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fool_rates_AdvBNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Champ Adv Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv/\") if \"test_images_champ\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv/\"+d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "targets = torch.hstack(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=torchvision.transforms.ToTensor())\n",
    "test_dataset.data    = None\n",
    "test_dataset.targets = None\n",
    "\n",
    "test_dataset.data    = images\n",
    "test_dataset.targets = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data loader with batch_size 1\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 2000 / 12288\n",
      "AdvBNN: 0.42992000000000025, BNN 0.5739999999999995, AdvBNN_med: 0.3815, AdvFFNN 0.036\n",
      "\n",
      " Processing 4000 / 12288\n",
      "AdvBNN: 0.4291799999999987, BNN 0.5716300000000026, AdvBNN_med: 0.3835, AdvFFNN 0.03725\n",
      "\n",
      " Processing 6000 / 12288\n",
      "AdvBNN: 0.4307333333333291, BNN 0.5744866666666713, AdvBNN_med: 0.387, AdvFFNN 0.038\n",
      "\n",
      " Processing 8000 / 12288\n",
      "AdvBNN: 0.43043999999999366, BNN 0.5755900000000099, AdvBNN_med: 0.386, AdvFFNN 0.038\n",
      "\n",
      " Processing 10000 / 12288\n",
      "AdvBNN: 0.4299399999999926, BNN 0.5748160000000144, AdvBNN_med: 0.3854, AdvFFNN 0.0364\n",
      "\n",
      " Processing 12000 / 12288\n",
      "AdvBNN: 0.4293733333333202, BNN 0.5734866666666837, AdvBNN_med: 0.38458333333333333, AdvFFNN 0.03675\n",
      "\n",
      " Processing 12288 / 12288\n",
      "AdvBNN: 0.4299251302083193, BNN 0.5734700520833509, AdvBNN_med: 0.3848470052083333, AdvFFNN 0.036946614583333336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "fool_rates_BNN         = []\n",
    "fool_rates_AdvBNN      = []\n",
    "fool_rates_AdvBNN_med  = []\n",
    "fool_rates_AdvFFNN     = []\n",
    "counter = 1\n",
    "for images, labels in test_loader:\n",
    "    print(\"\\r Processing %s / %s\" % (counter,len(test_loader.dataset.targets)), end=\"\")\n",
    "    images = images.view(-1, 28*28)\n",
    "    fool_rates_BNN.append(fooling_rate(sampled_models_BNN,images,labels))\n",
    "    fool_rates_AdvBNN.append(fooling_rate(sampled_models_AdvBNN,images,labels))\n",
    "    fool_rates_AdvBNN_med.append( 1 if fooling_rate(sampled_models_AdvBNN,images,labels) > 0.5 else 0 )\n",
    "    fool_rates_AdvFFNN.append(fooling_rate([AdvFFNN],images,labels))\n",
    "    if counter % 2000 == 0 or counter == len(test_loader.dataset.targets):\n",
    "        bnn_rate      = sum(fool_rates_BNN) / len(fool_rates_BNN)\n",
    "        advbnn_rate   = sum(fool_rates_AdvBNN) / len(fool_rates_AdvBNN)\n",
    "        advbnn_rate_m = sum(fool_rates_AdvBNN_med) / len(fool_rates_AdvBNN_med)\n",
    "        advffnn_rate  = sum(fool_rates_AdvFFNN) / len(fool_rates_AdvFFNN)\n",
    "        print(\"\\nAdvBNN: %s, BNN %s, AdvBNN_med: %s, AdvFFNN %s\\n\" % (advbnn_rate, bnn_rate,advbnn_rate_m, advffnn_rate))\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
