{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import tqdm\n",
    "import os\n",
    "import common\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "common.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for GPU\n",
    "# CUDA settings\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_type = 'lrt'  # 'bbb' or 'lrt'\n",
    "activation_type = 'softplus'  # 'softplus' or 'relu'\n",
    "priors={\n",
    "    'prior_mu': 0,\n",
    "    'prior_sigma': 0.1,\n",
    "    'posterior_mu_initial': (0, 0.1),  # (mean, std) normal_\n",
    "    'posterior_rho_initial': (-5, 0.1),  # (mean, std) normal_\n",
    "}\n",
    "lr_start = 0.001\n",
    "num_workers = 1\n",
    "valid_size = 0.2\n",
    "batch_size = 256\n",
    "train_ens = 1\n",
    "valid_ens = 1\n",
    "beta_type = 0.1  \n",
    "transform_cifar100 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "outputs = 100     # for cifar100, output classes = 10\n",
    "inputs = 3       # for cifar100, color channels = 3\n",
    "modelname = 'alexnet-cifar100.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR100(root='.', train=True, download=True, transform=transform_cifar100)\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, \n",
    "                                           sampler=valid_sampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBBAlexNet(common.ModuleWrapper):\n",
    "    '''The architecture of AlexNet with Bayesian Layers'''\n",
    "\n",
    "    def __init__(self, outputs, inputs, priors, layer_type='lrt', activation_type='softplus'):\n",
    "        super(BBBAlexNet, self).__init__()\n",
    "\n",
    "        self.num_classes = outputs\n",
    "        self.layer_type = layer_type\n",
    "        self.priors = priors\n",
    "\n",
    "        if layer_type=='lrt':\n",
    "            BBBLinear = common.layers.BBB_LRT_Linear\n",
    "            BBBConv2d = common.layers.BBB_LRT_Conv2d\n",
    "        elif layer_type=='bbb':\n",
    "            BBBLinear = common.layers.BBB_Linear\n",
    "            BBBConv2d = common.layers.BBB_Conv2d\n",
    "        else:\n",
    "            raise ValueError(\"Undefined layer_type\")\n",
    "        \n",
    "        if activation_type=='softplus':\n",
    "            self.act = nn.Softplus\n",
    "        elif activation_type=='relu':\n",
    "            self.act = nn.ReLU\n",
    "        else:\n",
    "            raise ValueError(\"Only softplus or relu supported\")\n",
    "\n",
    "        self.conv1 = BBBConv2d(inputs, 64, 11, stride=4, padding=5, bias=True, priors=self.priors)\n",
    "        self.act1 = self.act()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = BBBConv2d(64, 192, 5, padding=2, bias=True, priors=self.priors)\n",
    "        self.act2 = self.act()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = BBBConv2d(192, 384, 3, padding=1, bias=True, priors=self.priors)\n",
    "        self.act3 = self.act()\n",
    "\n",
    "        self.conv4 = BBBConv2d(384, 256, 3, padding=1, bias=True, priors=self.priors)\n",
    "        self.act4 = self.act()\n",
    "\n",
    "        self.conv5 = BBBConv2d(256, 128, 3, padding=1, bias=True, priors=self.priors)\n",
    "        self.act5 = self.act()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = common.layers.FlattenLayer(1 * 1 * 128)\n",
    "        self.classifier = BBBLinear(1 * 1 * 128, outputs, bias=True, priors=self.priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follows the procedure for sampling in the forward methods of BBBConv and \n",
    "# BBBLinear forward to create a fixed set of weights to use for the sampled model\n",
    "def sample_conv2d(bbb_layer):\n",
    "    conv_W_mu = bbb_layer.W_mu\n",
    "    conv_W_rho = bbb_layer.W_rho\n",
    "    conv_W_eps = torch.empty(conv_W_mu.size()).normal_(0,1).to(device)\n",
    "    conv_W_sigma = torch.log1p(torch.exp(conv_W_rho))\n",
    "    conv_weight = conv_W_mu + conv_W_eps * conv_W_sigma\n",
    "    if bbb_layer.use_bias:\n",
    "        conv_bias_mu = bbb_layer.bias_mu\n",
    "        conv_bias_rho = bbb_layer.bias_rho\n",
    "        conv_bias_eps = torch.empty(conv_bias_mu.size()).normal_(0,1).to(device)\n",
    "        conv_bias_sigma = torch.log1p(torch.exp(conv_bias_rho))\n",
    "        conv_bias = conv_bias_mu + conv_bias_eps * conv_bias_sigma\n",
    "    else:\n",
    "        conv_bias = None\n",
    "    return conv_weight.data, conv_bias.data\n",
    "\n",
    "def sample_linear(bbb_layer):\n",
    "        fc_W_mu = bbb_layer.W_mu\n",
    "        fc_W_rho = bbb_layer.W_rho\n",
    "        fc_W_eps = torch.empty(fc_W_mu.size()).normal_(0,1).to(device)\n",
    "        fc_W_sigma = torch.log1p(torch.exp(fc_W_rho))\n",
    "        fc_weight = fc_W_mu + fc_W_eps * fc_W_sigma\n",
    "        if bbb_layer.use_bias:\n",
    "            fc_bias_mu = bbb_layer.bias_mu\n",
    "            fc_bias_rho = bbb_layer.bias_rho\n",
    "            fc_bias_eps = torch.empty(fc_bias_mu.size()).normal_(0,1).to(device)\n",
    "            fc_bias_sigma = torch.log1p(torch.exp(fc_bias_rho))\n",
    "            fc_bias = fc_bias_mu + fc_bias_eps * fc_bias_sigma\n",
    "        else:\n",
    "            fc_bias = None\n",
    "        \n",
    "        return fc_weight.data, fc_bias.data\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, outputs, inputs, layer_type='lrt', activation_type='softplus'):\n",
    "        '''\n",
    "        Base AlexNet model that matches the architecture of BayesianAlexNet with randomly \n",
    "        initialized weights\n",
    "        '''\n",
    "        super(AlexNet, self).__init__()\n",
    "        \n",
    "        # initialization follows the BBBAlexNet initialization, changing\n",
    "        # BBBLinear and BBBConv2D layers to nn.Linear and nn.Conv2D\n",
    "        \n",
    "        if activation_type == 'softplus':\n",
    "            self.act = nn.Softplus\n",
    "        elif activation_type == 'relu':\n",
    "            self.act = nn.ReLU\n",
    "        else:\n",
    "            raise ValueError(\"Only softplus or relu supported\")\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inputs, 64, 11, stride=4, padding=5, bias=True)\n",
    "        self.act1 = self.act()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 192, 5, padding=2, bias=True)\n",
    "        self.act2 = self.act()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(192,384,3, padding=1, bias=True)\n",
    "        self.act3 = self.act()\n",
    "\n",
    "        self.conv4 = nn.Conv2d(384,256,3, padding=1, bias=True)\n",
    "        self.act4 = self.act()\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(256, 128, 3, padding=1, bias=True)\n",
    "        self.act5 = self.act()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # call x.view explicitly in forward\n",
    "        self.classifier = nn.Linear(1 * 1 * 128, outputs, bias=True)\n",
    "\n",
    "    def sample(self, bbbnet):\n",
    "        ### store activation function used by BNN, only relu and softplus  currently supported\n",
    "        self.act1 = bbbnet.act()\n",
    "        self.act2 = bbbnet.act()\n",
    "        self.act3 = bbbnet.act()\n",
    "        self.act4 = bbbnet.act()\n",
    "\n",
    "        ### maxpool\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=bbbnet.pool1.kernel_size, stride=bbbnet.pool1.stride)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=bbbnet.pool2.kernel_size, stride=bbbnet.pool2.stride)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=bbbnet.pool3.kernel_size, stride=bbbnet.pool3.stride)\n",
    "\n",
    "        ### Create Convolution layers\n",
    "        self.conv1 = nn.Conv2d(bbbnet.conv1.in_channels, bbbnet.conv1.out_channels, bbbnet.conv1.kernel_size,\n",
    "                                stride=bbbnet.conv1.stride, padding=bbbnet.conv1.padding, dilation=bbbnet.conv1.dilation,\n",
    "                                groups=bbbnet.conv1.groups)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(bbbnet.conv2.in_channels, bbbnet.conv2.out_channels, bbbnet.conv2.kernel_size,\n",
    "                        stride=bbbnet.conv2.stride, padding=bbbnet.conv2.padding, dilation=bbbnet.conv2.dilation,\n",
    "                        groups=bbbnet.conv2.groups)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(bbbnet.conv3.in_channels, bbbnet.conv3.out_channels, bbbnet.conv3.kernel_size,\n",
    "                                stride=bbbnet.conv3.stride, padding=bbbnet.conv3.padding, dilation=bbbnet.conv3.dilation,\n",
    "                                groups=bbbnet.conv3.groups)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(bbbnet.conv4.in_channels, bbbnet.conv4.out_channels, bbbnet.conv4.kernel_size,\n",
    "                        stride=bbbnet.conv4.stride, padding=bbbnet.conv4.padding, dilation=bbbnet.conv4.dilation,\n",
    "                        groups=bbbnet.conv4.groups)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(bbbnet.conv5.in_channels, bbbnet.conv5.out_channels, bbbnet.conv5.kernel_size,\n",
    "                        stride=bbbnet.conv5.stride, padding=bbbnet.conv5.padding, dilation=bbbnet.conv5.dilation,\n",
    "                        groups=bbbnet.conv5.groups)\n",
    "\n",
    "        # Sample convolutional layers\n",
    "        self.conv1.weight.data, self.conv1.bias.data = sample_conv2d(bbbnet.conv1)\n",
    "        self.conv2.weight.data, self.conv2.bias.data = sample_conv2d(bbbnet.conv2)\n",
    "        self.conv3.weight.data, self.conv3.bias.data = sample_conv2d(bbbnet.conv3)\n",
    "        self.conv4.weight.data, self.conv4.bias.data = sample_conv2d(bbbnet.conv4)\n",
    "        self.conv5.weight.data, self.conv5.bias.data = sample_conv2d(bbbnet.conv5)\n",
    "\n",
    "        ### Create Linear Layers\n",
    "        self.classifier = nn.Linear(bbbnet.classifier.in_features, bbbnet.classifier.out_features, bbbnet.classifier.use_bias)\n",
    "        self.classifier.weight.data, self.classifier.bias.data = sample_linear(bbbnet.classifier)            \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.act3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.act4(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.act5(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = x.view(-1, 1 * 1 * 128)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BBBAlexNet(outputs, inputs, priors, layer_type, activation_type).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_models(epochs = 10, K = 100, modelname = \"model-cnn.pt\"):\n",
    "    if os.path.exists(modelname):\n",
    "        print(\"File exists\")\n",
    "        return\n",
    "    # Train with ELBO and Adam (Bayes by Backprop + LRT)\n",
    "    criterion = common.metrics.ELBO(len(trainset)).to(device)\n",
    "    optimizer = Adam(net.parameters(), lr=lr_start)\n",
    "    lr_sched = lr_scheduler.ReduceLROnPlateau(optimizer, patience=6, verbose=True)\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        train_loss, train_acc, train_kl = common.train_model(net, optimizer, criterion, train_loader, \n",
    "                                                             num_ens=train_ens, beta_type=beta_type, epoch=epoch,\n",
    "                                                             num_epochs=epochs)\n",
    "        valid_loss, valid_acc = common.validate_model(net, criterion, valid_loader, num_ens=valid_ens, \n",
    "                                                      beta_type=beta_type, epoch=epoch, num_epochs=epochs)\n",
    "        lr_sched.step(valid_loss)\n",
    "        print('Epoch:%d, TrainLoss:%.3f, TrainAcc:%.3f, ValLoss:%.3f, ValAcc:%.3f, KL:%.3f' % (\n",
    "            epoch, train_loss, train_acc, valid_loss, valid_acc, train_kl))\n",
    "    # Sample k models from the posterior\n",
    "    nn_dicts = []\n",
    "    for i in range(K):\n",
    "        sample_model = AlexNet(outputs, inputs, layer_type, activation_type)\n",
    "        sample_model.sample(net)\n",
    "        nn_dicts += [sample_model.state_dict()]\n",
    "    # Save the models\n",
    "    torch.save(nn_dicts, modelname)\n",
    "    print(\"Saved %d models\" % K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(modelname, K = 100):\n",
    "    # Load the models\n",
    "    sampled_models = [AlexNet(outputs, inputs, layer_type, activation_type) for i in range(K)]\n",
    "    for net, state_dict in zip(sampled_models, torch.load(modelname)):\n",
    "        net.load_state_dict(state_dict)\n",
    "    print(\"Loaded %d sample models\" % K)\n",
    "    return sampled_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, TrainLoss:37070614.306, TrainAcc:0.020, ValLoss:28249598.950, ValAcc:0.027, KL:365088772.280\n",
      "Epoch:1, TrainLoss:23648562.904, TrainAcc:0.034, ValLoss:19910546.000, ValAcc:0.042, KL:234236578.752\n",
      "Epoch:2, TrainLoss:17356923.809, TrainAcc:0.052, ValLoss:15144468.975, ValAcc:0.057, KL:171402256.204\n",
      "Epoch:3, TrainLoss:13491576.121, TrainAcc:0.063, ValLoss:12017108.250, ValAcc:0.067, KL:132830326.522\n",
      "Epoch:4, TrainLoss:10859257.350, TrainAcc:0.074, ValLoss:9806308.150, ValAcc:0.077, KL:106547534.166\n",
      "Epoch:5, TrainLoss:8955101.927, TrainAcc:0.078, ValLoss:8170029.062, ValAcc:0.081, KL:87530780.688\n",
      "Epoch:6, TrainLoss:7519434.293, TrainAcc:0.084, ValLoss:6915087.725, ValAcc:0.085, KL:73194027.618\n",
      "Epoch:7, TrainLoss:6403313.487, TrainAcc:0.086, ValLoss:5924436.763, ValAcc:0.092, KL:62049268.306\n",
      "Epoch:8, TrainLoss:5514202.051, TrainAcc:0.093, ValLoss:5127934.125, ValAcc:0.096, KL:53176913.274\n",
      "Epoch:9, TrainLoss:4793116.105, TrainAcc:0.095, ValLoss:4476531.237, ValAcc:0.096, KL:45976573.936\n",
      "Epoch:10, TrainLoss:4197571.892, TrainAcc:0.102, ValLoss:3934246.994, ValAcc:0.104, KL:40039208.917\n",
      "Epoch:11, TrainLoss:3700238.779, TrainAcc:0.105, ValLoss:3478406.106, ValAcc:0.099, KL:35078694.650\n",
      "Epoch:12, TrainLoss:3279870.831, TrainAcc:0.111, ValLoss:3091658.606, ValAcc:0.112, KL:30887168.879\n",
      "Epoch:13, TrainLoss:2921053.252, TrainAcc:0.113, ValLoss:2760480.600, ValAcc:0.110, KL:27311810.637\n",
      "Epoch:14, TrainLoss:2612570.602, TrainAcc:0.114, ValLoss:2473319.131, ValAcc:0.111, KL:24236438.688\n",
      "Epoch:15, TrainLoss:2344880.221, TrainAcc:0.118, ValLoss:2224464.244, ValAcc:0.112, KL:21572464.357\n",
      "Epoch:16, TrainLoss:2111484.675, TrainAcc:0.122, ValLoss:2006650.247, ValAcc:0.117, KL:19250119.720\n",
      "Epoch:17, TrainLoss:1907284.200, TrainAcc:0.124, ValLoss:1814478.694, ValAcc:0.118, KL:17214788.299\n",
      "Epoch:18, TrainLoss:1727224.033, TrainAcc:0.126, ValLoss:1644380.941, ValAcc:0.126, KL:15422707.949\n",
      "Epoch:19, TrainLoss:1567690.134, TrainAcc:0.130, ValLoss:1495399.972, ValAcc:0.132, KL:13837817.153\n",
      "Epoch:20, TrainLoss:1426507.598, TrainAcc:0.129, ValLoss:1361716.581, ValAcc:0.136, KL:12430888.911\n",
      "Epoch:21, TrainLoss:1300445.588, TrainAcc:0.132, ValLoss:1243070.475, ValAcc:0.133, KL:11177899.306\n",
      "Epoch:22, TrainLoss:1187644.240, TrainAcc:0.134, ValLoss:1136835.900, ValAcc:0.132, KL:10059026.771\n",
      "Epoch:23, TrainLoss:1087018.383, TrainAcc:0.138, ValLoss:1040909.255, ValAcc:0.140, KL:9057459.873\n",
      "Epoch:24, TrainLoss:996561.213, TrainAcc:0.138, ValLoss:957594.113, ValAcc:0.135, KL:8159108.525\n",
      "Epoch:25, TrainLoss:915201.855, TrainAcc:0.142, ValLoss:880126.555, ValAcc:0.135, KL:7351791.395\n",
      "Epoch:26, TrainLoss:841690.504, TrainAcc:0.143, ValLoss:810449.047, ValAcc:0.135, KL:6624628.717\n",
      "Epoch:27, TrainLoss:775674.180, TrainAcc:0.146, ValLoss:745844.344, ValAcc:0.142, KL:5969366.742\n",
      "Epoch:28, TrainLoss:715820.307, TrainAcc:0.150, ValLoss:690159.322, ValAcc:0.142, KL:5377895.863\n",
      "Epoch:29, TrainLoss:662176.788, TrainAcc:0.149, ValLoss:640200.195, ValAcc:0.136, KL:4843857.025\n",
      "Epoch:30, TrainLoss:613439.848, TrainAcc:0.150, ValLoss:593112.030, ValAcc:0.145, KL:4361587.970\n",
      "Epoch:31, TrainLoss:568843.471, TrainAcc:0.154, ValLoss:551933.262, ValAcc:0.146, KL:3925294.823\n",
      "Epoch:32, TrainLoss:528737.124, TrainAcc:0.155, ValLoss:513084.369, ValAcc:0.148, KL:3530862.291\n",
      "Epoch:33, TrainLoss:492330.798, TrainAcc:0.159, ValLoss:479205.185, ValAcc:0.146, KL:3174082.196\n",
      "Epoch:34, TrainLoss:459365.303, TrainAcc:0.159, ValLoss:447487.386, ValAcc:0.147, KL:2851550.822\n",
      "Epoch:35, TrainLoss:429808.762, TrainAcc:0.162, ValLoss:420230.741, ValAcc:0.158, KL:2559869.774\n",
      "Epoch:36, TrainLoss:402964.584, TrainAcc:0.164, ValLoss:393635.224, ValAcc:0.158, KL:2296687.177\n",
      "Epoch:37, TrainLoss:378846.145, TrainAcc:0.167, ValLoss:370855.955, ValAcc:0.160, KL:2059070.314\n",
      "Epoch:38, TrainLoss:356766.520, TrainAcc:0.168, ValLoss:350993.209, ValAcc:0.159, KL:1844524.640\n",
      "Epoch:39, TrainLoss:336788.761, TrainAcc:0.167, ValLoss:331256.602, ValAcc:0.158, KL:1651087.278\n",
      "Epoch:40, TrainLoss:318341.500, TrainAcc:0.173, ValLoss:313073.385, ValAcc:0.170, KL:1476974.006\n",
      "Epoch:41, TrainLoss:302359.959, TrainAcc:0.176, ValLoss:297593.165, ValAcc:0.168, KL:1320470.260\n",
      "Epoch:42, TrainLoss:287344.935, TrainAcc:0.177, ValLoss:285046.392, ValAcc:0.171, KL:1179890.666\n",
      "Epoch:43, TrainLoss:274555.917, TrainAcc:0.180, ValLoss:271571.868, ValAcc:0.176, KL:1053918.980\n",
      "Epoch:44, TrainLoss:262576.805, TrainAcc:0.182, ValLoss:261423.452, ValAcc:0.174, KL:941135.498\n",
      "Epoch:45, TrainLoss:251989.517, TrainAcc:0.185, ValLoss:251148.220, ValAcc:0.170, KL:840817.882\n",
      "Epoch:46, TrainLoss:242143.334, TrainAcc:0.186, ValLoss:242927.330, ValAcc:0.173, KL:751358.726\n",
      "Epoch:47, TrainLoss:233862.025, TrainAcc:0.189, ValLoss:235359.233, ValAcc:0.172, KL:672045.801\n",
      "Epoch:48, TrainLoss:226239.008, TrainAcc:0.191, ValLoss:227182.702, ValAcc:0.184, KL:601549.228\n",
      "Epoch:49, TrainLoss:219424.397, TrainAcc:0.193, ValLoss:221310.614, ValAcc:0.177, KL:539469.785\n",
      "Epoch:50, TrainLoss:213421.915, TrainAcc:0.194, ValLoss:216052.585, ValAcc:0.183, KL:484834.250\n",
      "Epoch:51, TrainLoss:208242.077, TrainAcc:0.195, ValLoss:210111.720, ValAcc:0.189, KL:436897.757\n",
      "Epoch:52, TrainLoss:203368.840, TrainAcc:0.198, ValLoss:206131.522, ValAcc:0.180, KL:395285.097\n",
      "Epoch:53, TrainLoss:199090.924, TrainAcc:0.201, ValLoss:201780.270, ValAcc:0.196, KL:358961.978\n",
      "Epoch:54, TrainLoss:195276.178, TrainAcc:0.203, ValLoss:199135.905, ValAcc:0.196, KL:327361.105\n",
      "Epoch:55, TrainLoss:192251.634, TrainAcc:0.204, ValLoss:197217.857, ValAcc:0.185, KL:300269.565\n",
      "Epoch:56, TrainLoss:189385.930, TrainAcc:0.206, ValLoss:194822.822, ValAcc:0.184, KL:276876.921\n",
      "Epoch:57, TrainLoss:186970.528, TrainAcc:0.207, ValLoss:192936.046, ValAcc:0.190, KL:257180.293\n",
      "Epoch:58, TrainLoss:184754.191, TrainAcc:0.211, ValLoss:189999.207, ValAcc:0.196, KL:240343.269\n",
      "Epoch:59, TrainLoss:182837.502, TrainAcc:0.214, ValLoss:189319.687, ValAcc:0.199, KL:226237.436\n",
      "Epoch:60, TrainLoss:181447.717, TrainAcc:0.213, ValLoss:185558.230, ValAcc:0.201, KL:214273.862\n",
      "Epoch:61, TrainLoss:179855.557, TrainAcc:0.214, ValLoss:185476.701, ValAcc:0.197, KL:204601.438\n",
      "Epoch:62, TrainLoss:178263.988, TrainAcc:0.215, ValLoss:185364.043, ValAcc:0.205, KL:196486.277\n",
      "Epoch:63, TrainLoss:177590.716, TrainAcc:0.216, ValLoss:183711.943, ValAcc:0.203, KL:190119.020\n",
      "Epoch:64, TrainLoss:176697.212, TrainAcc:0.218, ValLoss:182223.656, ValAcc:0.208, KL:184833.731\n",
      "Epoch:65, TrainLoss:175747.544, TrainAcc:0.221, ValLoss:182705.864, ValAcc:0.205, KL:180517.936\n",
      "Epoch:66, TrainLoss:174884.307, TrainAcc:0.224, ValLoss:182685.385, ValAcc:0.196, KL:177156.311\n",
      "Epoch:67, TrainLoss:174367.971, TrainAcc:0.225, ValLoss:180785.659, ValAcc:0.213, KL:174546.703\n",
      "Epoch:68, TrainLoss:173606.414, TrainAcc:0.229, ValLoss:181074.699, ValAcc:0.214, KL:172577.489\n",
      "Epoch:69, TrainLoss:172669.880, TrainAcc:0.230, ValLoss:180482.497, ValAcc:0.210, KL:171184.195\n",
      "Epoch:70, TrainLoss:172887.845, TrainAcc:0.229, ValLoss:180477.565, ValAcc:0.204, KL:170384.919\n",
      "Epoch:71, TrainLoss:172244.676, TrainAcc:0.230, ValLoss:181030.195, ValAcc:0.217, KL:169915.876\n",
      "Epoch:72, TrainLoss:171921.203, TrainAcc:0.229, ValLoss:179960.968, ValAcc:0.218, KL:169487.720\n",
      "Epoch:73, TrainLoss:171572.946, TrainAcc:0.231, ValLoss:180374.597, ValAcc:0.206, KL:169481.374\n",
      "Epoch:74, TrainLoss:170928.873, TrainAcc:0.237, ValLoss:180265.709, ValAcc:0.210, KL:169773.618\n",
      "Epoch:75, TrainLoss:170614.326, TrainAcc:0.234, ValLoss:178833.675, ValAcc:0.224, KL:169795.161\n",
      "Epoch:76, TrainLoss:170715.632, TrainAcc:0.236, ValLoss:180249.198, ValAcc:0.214, KL:170628.453\n",
      "Epoch:77, TrainLoss:170063.984, TrainAcc:0.239, ValLoss:178949.170, ValAcc:0.215, KL:171103.050\n",
      "Epoch:78, TrainLoss:169815.608, TrainAcc:0.240, ValLoss:178926.273, ValAcc:0.218, KL:171653.632\n",
      "Epoch:79, TrainLoss:169652.148, TrainAcc:0.240, ValLoss:180085.911, ValAcc:0.215, KL:172265.813\n",
      "Epoch:80, TrainLoss:168905.192, TrainAcc:0.246, ValLoss:181159.707, ValAcc:0.212, KL:173092.149\n",
      "Epoch:81, TrainLoss:169085.554, TrainAcc:0.244, ValLoss:178371.695, ValAcc:0.220, KL:173984.822\n",
      "Epoch:82, TrainLoss:168737.171, TrainAcc:0.244, ValLoss:178375.605, ValAcc:0.219, KL:174858.874\n",
      "Epoch:83, TrainLoss:168409.220, TrainAcc:0.248, ValLoss:180836.889, ValAcc:0.214, KL:175594.995\n",
      "Epoch:84, TrainLoss:168316.394, TrainAcc:0.248, ValLoss:178653.289, ValAcc:0.224, KL:176543.697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:85, TrainLoss:168079.314, TrainAcc:0.250, ValLoss:178136.606, ValAcc:0.229, KL:177176.504\n",
      "Epoch:86, TrainLoss:167766.031, TrainAcc:0.250, ValLoss:178587.654, ValAcc:0.224, KL:178121.440\n",
      "Epoch:87, TrainLoss:167372.234, TrainAcc:0.252, ValLoss:180207.266, ValAcc:0.216, KL:178719.429\n",
      "Epoch:88, TrainLoss:167135.991, TrainAcc:0.254, ValLoss:178700.074, ValAcc:0.230, KL:179785.139\n",
      "Epoch:89, TrainLoss:167092.294, TrainAcc:0.253, ValLoss:178264.515, ValAcc:0.228, KL:180621.681\n",
      "Epoch:90, TrainLoss:166692.180, TrainAcc:0.254, ValLoss:177921.652, ValAcc:0.228, KL:181643.610\n",
      "Epoch:91, TrainLoss:166515.054, TrainAcc:0.256, ValLoss:178384.919, ValAcc:0.228, KL:182348.682\n",
      "Epoch:92, TrainLoss:165905.827, TrainAcc:0.259, ValLoss:179176.505, ValAcc:0.224, KL:183224.746\n",
      "Epoch:93, TrainLoss:166063.873, TrainAcc:0.260, ValLoss:178450.118, ValAcc:0.227, KL:184431.957\n",
      "Epoch:94, TrainLoss:166023.693, TrainAcc:0.262, ValLoss:177464.347, ValAcc:0.232, KL:185195.342\n",
      "Epoch:95, TrainLoss:165755.470, TrainAcc:0.261, ValLoss:177845.735, ValAcc:0.231, KL:186221.481\n",
      "Epoch:96, TrainLoss:165665.784, TrainAcc:0.260, ValLoss:178306.048, ValAcc:0.237, KL:187160.310\n",
      "Epoch:97, TrainLoss:165295.047, TrainAcc:0.262, ValLoss:179097.892, ValAcc:0.225, KL:187865.730\n",
      "Epoch:98, TrainLoss:164483.586, TrainAcc:0.265, ValLoss:176662.321, ValAcc:0.234, KL:188550.983\n",
      "Epoch:99, TrainLoss:164992.335, TrainAcc:0.265, ValLoss:177911.142, ValAcc:0.232, KL:189462.466\n",
      "Epoch:100, TrainLoss:164772.410, TrainAcc:0.267, ValLoss:178777.142, ValAcc:0.225, KL:190417.083\n",
      "Epoch:101, TrainLoss:164410.642, TrainAcc:0.267, ValLoss:178788.990, ValAcc:0.232, KL:191056.368\n",
      "Epoch:102, TrainLoss:164371.678, TrainAcc:0.270, ValLoss:181275.336, ValAcc:0.234, KL:191875.819\n",
      "Epoch:103, TrainLoss:163920.421, TrainAcc:0.271, ValLoss:178536.998, ValAcc:0.232, KL:192621.206\n",
      "Epoch:104, TrainLoss:163702.950, TrainAcc:0.272, ValLoss:179009.495, ValAcc:0.230, KL:193422.161\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:105, TrainLoss:163935.391, TrainAcc:0.270, ValLoss:177629.466, ValAcc:0.239, KL:194308.322\n",
      "Epoch:106, TrainLoss:161649.013, TrainAcc:0.279, ValLoss:177840.507, ValAcc:0.240, KL:193999.644\n",
      "Epoch:107, TrainLoss:160626.339, TrainAcc:0.282, ValLoss:176153.025, ValAcc:0.245, KL:193108.672\n",
      "Epoch:108, TrainLoss:160331.792, TrainAcc:0.286, ValLoss:178096.724, ValAcc:0.239, KL:192575.043\n",
      "Epoch:109, TrainLoss:160611.857, TrainAcc:0.284, ValLoss:177279.401, ValAcc:0.236, KL:192145.014\n",
      "Epoch:110, TrainLoss:160592.190, TrainAcc:0.284, ValLoss:177197.054, ValAcc:0.240, KL:191835.952\n",
      "Epoch:111, TrainLoss:160284.091, TrainAcc:0.285, ValLoss:176127.918, ValAcc:0.242, KL:191468.332\n",
      "Epoch:112, TrainLoss:159882.433, TrainAcc:0.283, ValLoss:177148.667, ValAcc:0.247, KL:191241.153\n",
      "Epoch:113, TrainLoss:160127.529, TrainAcc:0.284, ValLoss:176789.729, ValAcc:0.240, KL:190952.005\n",
      "Epoch:114, TrainLoss:160105.635, TrainAcc:0.285, ValLoss:176526.945, ValAcc:0.245, KL:190818.525\n",
      "Epoch:115, TrainLoss:159967.642, TrainAcc:0.286, ValLoss:177315.304, ValAcc:0.242, KL:190634.904\n",
      "Epoch:116, TrainLoss:159952.128, TrainAcc:0.285, ValLoss:176861.555, ValAcc:0.241, KL:190488.469\n",
      "Epoch:117, TrainLoss:159655.878, TrainAcc:0.285, ValLoss:177429.958, ValAcc:0.233, KL:190379.063\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:118, TrainLoss:159600.104, TrainAcc:0.283, ValLoss:176945.280, ValAcc:0.241, KL:190307.813\n",
      "Epoch:119, TrainLoss:159572.403, TrainAcc:0.285, ValLoss:177864.836, ValAcc:0.235, KL:190245.458\n",
      "Epoch:120, TrainLoss:159320.341, TrainAcc:0.283, ValLoss:176143.313, ValAcc:0.245, KL:190223.351\n",
      "Epoch:121, TrainLoss:159360.197, TrainAcc:0.287, ValLoss:176737.125, ValAcc:0.238, KL:190203.117\n",
      "Epoch:122, TrainLoss:159531.152, TrainAcc:0.286, ValLoss:176526.849, ValAcc:0.242, KL:190175.750\n",
      "Epoch:123, TrainLoss:159703.921, TrainAcc:0.285, ValLoss:176850.901, ValAcc:0.240, KL:190152.280\n",
      "Epoch:124, TrainLoss:159525.942, TrainAcc:0.286, ValLoss:176654.951, ValAcc:0.249, KL:190137.591\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:125, TrainLoss:159571.703, TrainAcc:0.287, ValLoss:177003.134, ValAcc:0.240, KL:190113.729\n",
      "Epoch:126, TrainLoss:159459.537, TrainAcc:0.287, ValLoss:176522.874, ValAcc:0.243, KL:190099.405\n",
      "Epoch:127, TrainLoss:159453.533, TrainAcc:0.288, ValLoss:179577.150, ValAcc:0.233, KL:190099.313\n",
      "Epoch:128, TrainLoss:159157.554, TrainAcc:0.283, ValLoss:177729.877, ValAcc:0.238, KL:190097.237\n",
      "Epoch:129, TrainLoss:159341.504, TrainAcc:0.286, ValLoss:176766.285, ValAcc:0.244, KL:190094.731\n",
      "Epoch:130, TrainLoss:159394.454, TrainAcc:0.287, ValLoss:176992.941, ValAcc:0.242, KL:190094.152\n",
      "Epoch:131, TrainLoss:159237.668, TrainAcc:0.287, ValLoss:176319.990, ValAcc:0.236, KL:190093.789\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:132, TrainLoss:159407.006, TrainAcc:0.284, ValLoss:177610.536, ValAcc:0.242, KL:190091.784\n",
      "Epoch:133, TrainLoss:159447.729, TrainAcc:0.288, ValLoss:176769.302, ValAcc:0.239, KL:190089.722\n",
      "Epoch:134, TrainLoss:159336.186, TrainAcc:0.286, ValLoss:178184.314, ValAcc:0.241, KL:190089.495\n",
      "Epoch:135, TrainLoss:159339.118, TrainAcc:0.286, ValLoss:177160.800, ValAcc:0.243, KL:190089.257\n",
      "Epoch:136, TrainLoss:159415.694, TrainAcc:0.286, ValLoss:176403.402, ValAcc:0.240, KL:190089.060\n",
      "Epoch:137, TrainLoss:159256.287, TrainAcc:0.287, ValLoss:177547.034, ValAcc:0.236, KL:190088.762\n",
      "Epoch:138, TrainLoss:159168.604, TrainAcc:0.286, ValLoss:177838.464, ValAcc:0.240, KL:190088.438\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:139, TrainLoss:159017.552, TrainAcc:0.287, ValLoss:177549.302, ValAcc:0.240, KL:190087.976\n",
      "Epoch:140, TrainLoss:159253.469, TrainAcc:0.288, ValLoss:176491.850, ValAcc:0.242, KL:190087.827\n",
      "Epoch:141, TrainLoss:159356.822, TrainAcc:0.286, ValLoss:176218.130, ValAcc:0.238, KL:190087.796\n",
      "Epoch:142, TrainLoss:159218.960, TrainAcc:0.288, ValLoss:177929.467, ValAcc:0.232, KL:190087.768\n",
      "Epoch:143, TrainLoss:159254.447, TrainAcc:0.285, ValLoss:176410.359, ValAcc:0.240, KL:190087.750\n",
      "Epoch:144, TrainLoss:159324.923, TrainAcc:0.287, ValLoss:176725.205, ValAcc:0.247, KL:190087.727\n",
      "Epoch:145, TrainLoss:159704.731, TrainAcc:0.284, ValLoss:178089.953, ValAcc:0.242, KL:190087.719\n",
      "Epoch:146, TrainLoss:159704.157, TrainAcc:0.283, ValLoss:176930.838, ValAcc:0.238, KL:190087.710\n",
      "Epoch:147, TrainLoss:159270.777, TrainAcc:0.287, ValLoss:176820.255, ValAcc:0.241, KL:190087.691\n",
      "Epoch:148, TrainLoss:159128.224, TrainAcc:0.288, ValLoss:176956.877, ValAcc:0.241, KL:190087.672\n",
      "Epoch:149, TrainLoss:159638.410, TrainAcc:0.286, ValLoss:178738.613, ValAcc:0.237, KL:190087.655\n",
      "Epoch:150, TrainLoss:159459.496, TrainAcc:0.287, ValLoss:177225.548, ValAcc:0.235, KL:190087.634\n",
      "Epoch:151, TrainLoss:159426.377, TrainAcc:0.287, ValLoss:177427.774, ValAcc:0.241, KL:190087.620\n",
      "Epoch:152, TrainLoss:159204.900, TrainAcc:0.287, ValLoss:176775.514, ValAcc:0.235, KL:190087.584\n",
      "Epoch:153, TrainLoss:159253.294, TrainAcc:0.288, ValLoss:177220.419, ValAcc:0.236, KL:190087.556\n",
      "Epoch:154, TrainLoss:159285.443, TrainAcc:0.290, ValLoss:175798.446, ValAcc:0.245, KL:190087.538\n",
      "Epoch:155, TrainLoss:158969.170, TrainAcc:0.290, ValLoss:177967.296, ValAcc:0.232, KL:190087.500\n",
      "Epoch:156, TrainLoss:159382.694, TrainAcc:0.287, ValLoss:178360.121, ValAcc:0.238, KL:190087.457\n",
      "Epoch:157, TrainLoss:159522.911, TrainAcc:0.284, ValLoss:175915.831, ValAcc:0.248, KL:190087.426\n",
      "Epoch:158, TrainLoss:159424.934, TrainAcc:0.285, ValLoss:175606.982, ValAcc:0.241, KL:190087.407\n",
      "Epoch:159, TrainLoss:159382.355, TrainAcc:0.288, ValLoss:175534.940, ValAcc:0.247, KL:190087.380\n",
      "Epoch:160, TrainLoss:159233.586, TrainAcc:0.288, ValLoss:176878.830, ValAcc:0.241, KL:190087.364\n",
      "Epoch:161, TrainLoss:159751.171, TrainAcc:0.281, ValLoss:174907.807, ValAcc:0.244, KL:190087.337\n",
      "Epoch:162, TrainLoss:158994.252, TrainAcc:0.288, ValLoss:175657.059, ValAcc:0.238, KL:190087.334\n",
      "Epoch:163, TrainLoss:159333.252, TrainAcc:0.287, ValLoss:175676.923, ValAcc:0.245, KL:190087.304\n",
      "Epoch:164, TrainLoss:159150.452, TrainAcc:0.286, ValLoss:176510.142, ValAcc:0.239, KL:190087.280\n",
      "Epoch:165, TrainLoss:159444.376, TrainAcc:0.284, ValLoss:177615.591, ValAcc:0.242, KL:190087.253\n",
      "Epoch:166, TrainLoss:158900.808, TrainAcc:0.288, ValLoss:177547.577, ValAcc:0.234, KL:190087.213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:167, TrainLoss:158973.048, TrainAcc:0.287, ValLoss:176609.341, ValAcc:0.241, KL:190087.188\n",
      "Epoch:168, TrainLoss:159411.715, TrainAcc:0.286, ValLoss:177892.668, ValAcc:0.236, KL:190087.138\n",
      "Epoch:169, TrainLoss:159580.539, TrainAcc:0.286, ValLoss:176440.416, ValAcc:0.242, KL:190087.118\n",
      "Epoch:170, TrainLoss:159631.456, TrainAcc:0.285, ValLoss:176369.316, ValAcc:0.244, KL:190087.109\n",
      "Epoch:171, TrainLoss:159424.497, TrainAcc:0.284, ValLoss:177797.868, ValAcc:0.237, KL:190087.073\n",
      "Epoch:172, TrainLoss:159429.712, TrainAcc:0.287, ValLoss:176248.566, ValAcc:0.245, KL:190087.050\n",
      "Epoch:173, TrainLoss:159114.578, TrainAcc:0.288, ValLoss:177414.308, ValAcc:0.239, KL:190087.027\n",
      "Epoch:174, TrainLoss:159140.350, TrainAcc:0.289, ValLoss:177424.152, ValAcc:0.243, KL:190087.002\n",
      "Epoch:175, TrainLoss:159764.271, TrainAcc:0.284, ValLoss:176792.519, ValAcc:0.242, KL:190086.980\n",
      "Epoch:176, TrainLoss:158876.278, TrainAcc:0.288, ValLoss:176188.513, ValAcc:0.244, KL:190086.951\n",
      "Epoch:177, TrainLoss:159470.495, TrainAcc:0.286, ValLoss:177691.374, ValAcc:0.238, KL:190086.925\n",
      "Epoch:178, TrainLoss:159072.544, TrainAcc:0.288, ValLoss:176279.978, ValAcc:0.244, KL:190086.897\n",
      "Epoch:179, TrainLoss:159287.137, TrainAcc:0.285, ValLoss:177739.015, ValAcc:0.238, KL:190086.892\n",
      "Epoch:180, TrainLoss:159485.283, TrainAcc:0.286, ValLoss:179018.850, ValAcc:0.234, KL:190086.854\n",
      "Epoch:181, TrainLoss:159050.153, TrainAcc:0.285, ValLoss:176190.871, ValAcc:0.245, KL:190086.828\n",
      "Epoch:182, TrainLoss:159140.282, TrainAcc:0.287, ValLoss:177320.444, ValAcc:0.241, KL:190086.785\n",
      "Epoch:183, TrainLoss:159354.150, TrainAcc:0.286, ValLoss:176498.938, ValAcc:0.242, KL:190086.750\n",
      "Epoch:184, TrainLoss:159534.046, TrainAcc:0.288, ValLoss:175534.125, ValAcc:0.242, KL:190086.729\n",
      "Epoch:185, TrainLoss:159467.567, TrainAcc:0.286, ValLoss:176987.746, ValAcc:0.237, KL:190086.713\n",
      "Epoch:186, TrainLoss:159676.357, TrainAcc:0.285, ValLoss:177335.191, ValAcc:0.240, KL:190086.695\n",
      "Epoch:187, TrainLoss:159480.466, TrainAcc:0.287, ValLoss:176971.960, ValAcc:0.240, KL:190086.675\n",
      "Epoch:188, TrainLoss:159344.406, TrainAcc:0.286, ValLoss:177163.063, ValAcc:0.241, KL:190086.657\n",
      "Epoch:189, TrainLoss:159603.709, TrainAcc:0.285, ValLoss:177495.529, ValAcc:0.239, KL:190086.654\n",
      "Epoch:190, TrainLoss:158907.254, TrainAcc:0.290, ValLoss:176676.506, ValAcc:0.241, KL:190086.622\n",
      "Epoch:191, TrainLoss:159549.723, TrainAcc:0.287, ValLoss:176977.662, ValAcc:0.242, KL:190086.590\n",
      "Epoch:192, TrainLoss:159045.059, TrainAcc:0.287, ValLoss:176367.093, ValAcc:0.245, KL:190086.576\n",
      "Epoch:193, TrainLoss:159633.455, TrainAcc:0.286, ValLoss:176374.958, ValAcc:0.241, KL:190086.552\n",
      "Epoch:194, TrainLoss:159410.931, TrainAcc:0.284, ValLoss:177099.891, ValAcc:0.240, KL:190086.531\n",
      "Epoch:195, TrainLoss:159065.792, TrainAcc:0.290, ValLoss:176387.940, ValAcc:0.240, KL:190086.502\n",
      "Epoch:196, TrainLoss:159646.251, TrainAcc:0.285, ValLoss:176523.743, ValAcc:0.241, KL:190086.490\n",
      "Epoch:197, TrainLoss:159283.337, TrainAcc:0.286, ValLoss:178162.780, ValAcc:0.243, KL:190086.477\n",
      "Epoch:198, TrainLoss:159432.200, TrainAcc:0.285, ValLoss:178788.722, ValAcc:0.231, KL:190086.468\n",
      "Epoch:199, TrainLoss:159340.087, TrainAcc:0.288, ValLoss:177357.246, ValAcc:0.237, KL:190086.447\n",
      "Saved 100 models\n",
      "Loaded 100 sample models\n"
     ]
    }
   ],
   "source": [
    "train_and_save_models(epochs = 200, K = 100, modelname = modelname)\n",
    "sampled_models = load_models(modelname, K = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.CIFAR100(root='.', train=False, download=True, transform=transform_cifar100)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=1, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch and flatten the input\n",
    "images, targets = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([49])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(model, images, loss_target = None):\n",
    "    output = model(images)\n",
    "    output = torch.nn.LogSoftmax(dim=-1)(output)\n",
    "    which_class = torch.argmax(output).item()\n",
    "    if loss_target:\n",
    "        loss, target = loss_target\n",
    "        loss(output, target).backward()\n",
    "    return which_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def otcm(images, eps, saliency):\n",
    "    return torch.clamp(images.clone()-eps*saliency, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many models can an adversarial example fool?\n",
    "def how_many_can_it_fool(sampled_models, eps, saliency):\n",
    "    fool = 0\n",
    "    for k in range(len(sampled_models)):\n",
    "        # Forward pass on sampled model k\n",
    "        old_class = forward_pass(sampled_models[k], images)\n",
    "        # One step Target Class Method (OTCM); saliency is noise\n",
    "        new_images = otcm(images, eps, saliency)\n",
    "        # Forward pass again on adv. example\n",
    "        new_class = forward_pass(sampled_models[k], new_images)\n",
    "        # If we change the class, we fool the model\n",
    "        fool += int(old_class != new_class)\n",
    "    return fool/len(sampled_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect noises (saliencies)\n",
    "EPS = 0.1\n",
    "saliencies = []\n",
    "how_many_fooled = []\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "for k in range(len(sampled_models)):\n",
    "    # Forward pass\n",
    "    # Compute loss w.r.t. an incorrect class\n",
    "    # Note that we just have to ensure this class is different from targets\n",
    "    images.grad = None\n",
    "    images.requires_grad = True\n",
    "    old_class = forward_pass(sampled_models[k], images, [torch.nn.NLLLoss(), torch.tensor([1])])\n",
    "    # Compute adversarial example\n",
    "    new_images = otcm(images, EPS, images.grad.sign())\n",
    "    # Forward pass on adv. example\n",
    "    new_class = forward_pass(sampled_models[k], new_images)\n",
    "    if old_class != new_class:\n",
    "        # How many models can this adv. example fool?\n",
    "        how_many_fooled += [how_many_can_it_fool(sampled_models, EPS, images.grad.sign())]\n",
    "        saliencies += [images.grad.sign().squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# distributional saliency map\n",
    "saliencies = torch.stack(saliencies)\n",
    "print(saliencies.shape)\n",
    "unbatched_shape = saliencies.shape[1:]\n",
    "print(unbatched_shape)\n",
    "newsaliency = torch.zeros(unbatched_shape)\n",
    "\n",
    "for i in range(unbatched_shape[0]):\n",
    "    for j in range(unbatched_shape[1]):\n",
    "        for k in range(unbatched_shape[2]):\n",
    "            # choose median perturbation\n",
    "            newsaliency[i, j, k] = np.percentile(saliencies[:, i, j, k].numpy(), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "print(how_many_can_it_fool(sampled_models, EPS, newsaliency))\n",
    "new_images = otcm(images, EPS, newsaliency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9451"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(how_many_fooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<MaxBackward1>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.subplot(1, 3, 1)\n",
    "images = images.squeeze() # squeeze out batch dimension\n",
    "image_transpose = np.transpose( images.detach().numpy() , (1,2,0))  \n",
    "plt.imshow(image_transpose)\n",
    "plt.subplot(1, 3, 2)\n",
    "perturbation = newsaliency * EPS\n",
    "perturbation_transpose = np.transpose(perturbation.detach().numpy(), (1,2,0))\n",
    "plt.imshow(perturbation_transpose, vmin=-1., vmax=1.)\n",
    "plt.subplot(1, 3, 3)\n",
    "new_images = new_images.squeeze()\n",
    "print(torch.max(new_images))\n",
    "new_images_transpose = np.transpose(new_images.detach().numpy(), (1,2,0))\n",
    "plt.imshow(new_images_transpose)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
