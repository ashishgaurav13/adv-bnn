{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import tqdm\n",
    "import os,sys\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "\n",
    "\n",
    "import re, pickle\n",
    "from torch.utils.data import DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "common.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_type = 'lrt'  # 'bbb' or 'lrt'\n",
    "activation_type = 'softplus'  # 'softplus' or 'relu'\n",
    "priors={\n",
    "    'prior_mu': 0,\n",
    "    'prior_sigma': 0.1,\n",
    "    'posterior_mu_initial': (0, 0.1),  # (mean, std) normal_\n",
    "    'posterior_rho_initial': (-5, 0.1),  # (mean, std) normal_\n",
    "}\n",
    "lr_start = 0.001\n",
    "num_workers = 1\n",
    "valid_size = 0.2\n",
    "batch_size = 256\n",
    "train_ens = 1\n",
    "valid_ens = 1\n",
    "beta_type = 0.1  \n",
    "transform_mnist = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "outputs = 10\n",
    "inputs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='.', train=True, download=True, transform=transform_mnist)\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, \n",
    "                                           sampler=valid_sampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBBLeNet(common.ModuleWrapper):\n",
    "    '''The architecture of LeNet with Bayesian Layers'''\n",
    "\n",
    "    def __init__(self, outputs, inputs, priors, layer_type='lrt', activation_type='softplus'):\n",
    "        super(BBBLeNet, self).__init__()\n",
    "\n",
    "        self.num_classes = outputs\n",
    "        self.layer_type = layer_type\n",
    "        self.priors = priors\n",
    "\n",
    "        if layer_type=='lrt':\n",
    "            BBBLinear = common.layers.BBB_LRT_Linear\n",
    "            BBBConv2d = common.layers.BBB_LRT_Conv2d\n",
    "        elif layer_type=='bbb':\n",
    "            BBBLinear = common.layers.BBB_Linear\n",
    "            BBBConv2d = common.layers.BBB_Conv2d\n",
    "        else:\n",
    "            raise ValueError(\"Undefined layer_type\")\n",
    "        \n",
    "        if activation_type=='softplus':\n",
    "            self.act = nn.Softplus\n",
    "        elif activation_type=='relu':\n",
    "            self.act = nn.ReLU\n",
    "        else:\n",
    "            raise ValueError(\"Only softplus or relu supported\")\n",
    "\n",
    "        self.conv1 = BBBConv2d(inputs, 6, 5, padding=0, bias=True, priors=self.priors)\n",
    "        self.act1 = self.act()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = BBBConv2d(6, 16, 5, padding=0, bias=True, priors=self.priors)\n",
    "        self.act2 = self.act()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = common.layers.FlattenLayer(5 * 5 * 16)\n",
    "        self.fc1 = BBBLinear(5 * 5 * 16, 120, bias=True, priors=self.priors)\n",
    "        self.act3 = self.act()\n",
    "\n",
    "        self.fc2 = BBBLinear(120, 84, bias=True, priors=self.priors)\n",
    "        self.act4 = self.act()\n",
    "\n",
    "        self.fc3 = BBBLinear(84, outputs, bias=True, priors=self.priors)\n",
    "        \n",
    "        \n",
    "class LeNet(nn.Module):\n",
    "\n",
    "    def __init__(self, outputs, inputs, layer_type='lrt', activation_type='softplus'):\n",
    "        '''\n",
    "        Base LeNet model that matches the architecture of BayesianLeNet with randomly \n",
    "        initialized weights\n",
    "        '''\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        # initialization follows the BBBLeNet initialization, changing\n",
    "        # BBBLinear and BBBConv2D layers to nn.Linear and nn.Conv2D\n",
    "        \n",
    "        if activation_type == 'softplus':\n",
    "            self.act = nn.Softplus\n",
    "        elif activation_type == 'relu':\n",
    "            self.act = nn.ReLU\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inputs, 6, 5, padding=0, bias=True)\n",
    "        self.act1 = self.act()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, padding=0, bias=True)\n",
    "        self.act2 = self.act()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(5 * 5 * 16, 120, bias=True)\n",
    "        self.act3 = self.act()\n",
    "        self.fc2 = nn.Linear(120, 84, bias=True)\n",
    "        self.act4 = self.act()\n",
    "        self.fc3 = nn.Linear(84, outputs, bias=True)\n",
    "\n",
    "\n",
    "    def sample(self, bbbnet):\n",
    "        '''\n",
    "        Takes in a BBBLeNet instance and copies the structure into a LeNet model.\n",
    "        Replaces the BBBLinear and BBBConv2D that uses sampling in their forward steps\n",
    "        with regular nn.Linear and nn.Conv2d layers whose weights are initialized by \n",
    "        sampling the BBBLeNet model.\n",
    "        '''    \n",
    "        ### store activation function used by BNN, only relu and softplus  currently supported\n",
    "        self.act1 = bbbnet.act()\n",
    "        self.act2 = bbbnet.act()\n",
    "        self.act3 = bbbnet.act()\n",
    "        self.act4 = bbbnet.act()\n",
    "\n",
    "        ### maxpool\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=bbbnet.pool1.kernel_size, stride=bbbnet.pool1.stride)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=bbbnet.pool2.kernel_size, stride=bbbnet.pool2.stride)\n",
    "        \n",
    "        ### Create Convolution layers\n",
    "        self.conv1 = nn.Conv2d(bbbnet.conv1.in_channels, bbbnet.conv1.out_channels, bbbnet.conv1.kernel_size,\n",
    "                                stride=bbbnet.conv1.stride, padding=bbbnet.conv1.padding, dilation=bbbnet.conv1.dilation,\n",
    "                                groups=bbbnet.conv1.groups)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(bbbnet.conv2.in_channels, bbbnet.conv2.out_channels, bbbnet.conv2.kernel_size,\n",
    "                        stride=bbbnet.conv2.stride, padding=bbbnet.conv2.padding, dilation=bbbnet.conv2.dilation,\n",
    "                        groups=bbbnet.conv2.groups)\n",
    "        \n",
    "        # follows the procedure for sampling in the forward methods of BBBConv and \n",
    "        # BBBLinearforward to create a fixed set of weights to use for the sampled model\n",
    "\n",
    "        conv1_W_mu = bbbnet.conv1.W_mu\n",
    "        conv1_W_rho = bbbnet.conv1.W_rho\n",
    "        conv1_W_eps = torch.empty(conv1_W_mu.size()).normal_(0,1)\n",
    "        conv1_W_sigma = torch.log1p(torch.exp(conv1_W_rho))\n",
    "        conv1_weight = conv1_W_mu + conv1_W_eps * conv1_W_sigma\n",
    "        if bbbnet.conv1.use_bias:\n",
    "            conv1_bias_mu = bbbnet.conv1.bias_mu\n",
    "            conv1_bias_rho = bbbnet.conv1.bias_rho\n",
    "            conv1_bias_eps = torch.empty(conv1_bias_mu.size()).normal_(0,1)\n",
    "            conv1_bias_sigma = torch.log1p(torch.exp(conv1_bias_rho))\n",
    "            conv1_bias = conv1_bias_mu + conv1_bias_eps * conv1_bias_sigma\n",
    "        else:\n",
    "            conv1_bias = None\n",
    "        self.conv1.weight.data = conv1_weight.data\n",
    "        self.conv1.bias.data = conv1_bias.data\n",
    "\n",
    "\n",
    "        conv2_W_mu = bbbnet.conv2.W_mu\n",
    "        conv2_W_rho = bbbnet.conv2.W_rho\n",
    "        conv2_W_eps = torch.empty(conv2_W_mu.size()).normal_(0,1)\n",
    "        conv2_W_sigma = torch.log1p(torch.exp(conv2_W_rho))\n",
    "        conv2_weight = conv2_W_mu + conv2_W_eps * conv2_W_sigma\n",
    "        if bbbnet.conv2.use_bias:\n",
    "            conv2_bias_mu = bbbnet.conv2.bias_mu\n",
    "            conv2_bias_rho = bbbnet.conv2.bias_rho\n",
    "            conv2_bias_eps = torch.empty(conv2_bias_mu.size()).normal_(0,1)\n",
    "            conv2_bias_sigma = torch.log1p(torch.exp(conv2_bias_rho))\n",
    "            conv2_bias = conv2_bias_mu + conv2_bias_eps * conv2_bias_sigma\n",
    "        else:\n",
    "            conv2_bias = None\n",
    "        self.conv2.weight.data = conv2_weight.data\n",
    "        self.conv2.bias.data = conv2_bias.data\n",
    "        \n",
    "        ### Create Linear Layers\n",
    "        self.fc1 = nn.Linear(bbbnet.fc1.in_features, bbbnet.fc1.out_features, bbbnet.fc1.use_bias)\n",
    "        self.fc2 = nn.Linear(bbbnet.fc2.in_features, bbbnet.fc2.out_features, bbbnet.fc2.use_bias)\n",
    "        self.fc3 = nn.Linear(bbbnet.fc3.in_features, bbbnet.fc3.out_features, bbbnet.fc3.use_bias)\n",
    "\n",
    "        fc1_W_mu = bbbnet.fc1.W_mu\n",
    "        fc1_W_rho = bbbnet.fc1.W_rho\n",
    "        fc1_W_eps = torch.empty(fc1_W_mu.size()).normal_(0,1)\n",
    "        fc1_W_sigma = torch.log1p(torch.exp(fc1_W_rho))\n",
    "        fc1_weight = fc1_W_mu + fc1_W_eps * fc1_W_sigma\n",
    "        if bbbnet.fc1.use_bias:\n",
    "            fc1_bias_mu = bbbnet.fc1.bias_mu\n",
    "            fc1_bias_rho = bbbnet.fc1.bias_rho\n",
    "            fc1_bias_eps = torch.empty(fc1_bias_mu.size()).normal_(0,1)\n",
    "            fc1_bias_sigma = torch.log1p(torch.exp(fc1_bias_rho))\n",
    "            fc1_bias = fc1_bias_mu + fc1_bias_eps * fc1_bias_sigma\n",
    "        else:\n",
    "            fc1_bias = None\n",
    "        self.fc1.weight.data = fc1_weight.data\n",
    "        self.fc1.bias.data = fc1_bias.data\n",
    "\n",
    "        fc2_W_mu = bbbnet.fc2.W_mu\n",
    "        fc2_W_rho = bbbnet.fc2.W_rho\n",
    "        fc2_W_eps = torch.empty(fc2_W_mu.size()).normal_(0,1)\n",
    "        fc2_W_sigma = torch.log1p(torch.exp(fc2_W_rho))\n",
    "        fc2_weight = fc2_W_mu + fc2_W_eps * fc2_W_sigma\n",
    "        if bbbnet.fc2.use_bias:\n",
    "            fc2_bias_mu = bbbnet.fc2.bias_mu\n",
    "            fc2_bias_rho = bbbnet.fc2.bias_rho\n",
    "            fc2_bias_eps = torch.empty(fc2_bias_mu.size()).normal_(0,1)\n",
    "            fc2_bias_sigma = torch.log1p(torch.exp(fc2_bias_rho))\n",
    "            fc2_bias = fc2_bias_mu + fc2_bias_eps * fc2_bias_sigma\n",
    "        else:\n",
    "            fc2_bias = None\n",
    "        self.fc2.weight.data = fc2_weight.data\n",
    "        self.fc2.bias.data = fc2_bias.data\n",
    "\n",
    "        fc3_W_mu = bbbnet.fc3.W_mu\n",
    "        fc3_W_rho = bbbnet.fc3.W_rho\n",
    "        fc3_W_eps = torch.empty(fc3_W_mu.size()).normal_(0,1)\n",
    "        fc3_W_sigma = torch.log1p(torch.exp(fc3_W_rho))\n",
    "        fc3_weight = fc3_W_mu + fc3_W_eps * fc3_W_sigma\n",
    "        if bbbnet.fc3.use_bias:\n",
    "            fc3_bias_mu = bbbnet.fc3.bias_mu\n",
    "            fc3_bias_rho = bbbnet.fc3.bias_rho\n",
    "            fc3_bias_eps = torch.empty(fc3_bias_mu.size()).normal_(0,1)\n",
    "            fc3_bias_sigma = torch.log1p(torch.exp(fc3_bias_rho))\n",
    "            fc3_bias = fc3_bias_mu + fc3_bias_eps * fc3_bias_sigma\n",
    "        else:\n",
    "            fc3_bias = None\n",
    "        self.fc3.weight.data = fc3_weight.data\n",
    "        self.fc3.bias.data = fc3_bias.data\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Forward method follow the order of BayesianLeNet\n",
    "        '''\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(-1, 5 * 5 * 16)\n",
    "        x = self.fc1(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BBBLeNet(outputs, inputs, priors, layer_type, activation_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(K = 100, modelname=\"models/model-cnn.pt\"):\n",
    "    # Load the models\n",
    "    sampled_models = [LeNet(outputs, inputs, layer_type, activation_type) for i in range(K)]\n",
    "    for net, state_dict in zip(sampled_models, torch.load(modelname)):\n",
    "        net.load_state_dict(state_dict)\n",
    "    print(\"Loaded %d sample models\" % K)\n",
    "    return sampled_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Test Accuracy (eps=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_back = transforms.Compose([transforms.Resize((28,28))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_0.05/\") if \"test_images_med\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_0.05/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "images  = images[:,0,:,:]\n",
    "\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_test_dataset.data    = None\n",
    "adv_test_dataset.targets = None\n",
    "\n",
    "adv_test_dataset.data    = images\n",
    "adv_test_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_test_loader = torch.utils.data.DataLoader(adv_test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_0.05/\") if \"test_images_champ\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_0.05/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "images  = images[:,0,:,:]\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_champ_test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_champ_test_dataset.data    = None\n",
    "adv_champ_test_dataset.targets = None\n",
    "\n",
    "adv_champ_test_dataset.data    = images\n",
    "adv_champ_test_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_champ_test_loader = torch.utils.data.DataLoader(adv_champ_test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_0.05/\") if \"test_images_mean\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_0.05/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "images  = images[:,0,:,:]\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_mean_test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_mean_test_dataset.data    = None\n",
    "adv_mean_test_dataset.targets = None\n",
    "\n",
    "adv_mean_test_dataset.data    = images\n",
    "adv_mean_test_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_mean_test_loader = torch.utils.data.DataLoader(adv_mean_test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_0.18/\") if \"test_images_med\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_0.18/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "images  = images[:,0,:,:]\n",
    "\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_test_18_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_test_18_dataset.data    = None\n",
    "adv_test_18_dataset.targets = None\n",
    "\n",
    "adv_test_18_dataset.data    = images\n",
    "adv_test_18_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_test_18_loader = torch.utils.data.DataLoader(adv_test_18_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_0.18/\") if \"test_images_champ\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_0.18/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "images  = images[:,0,:,:]\n",
    "\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_champ_test_18_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_champ_test_18_dataset.data    = None\n",
    "adv_champ_test_18_dataset.targets = None\n",
    "\n",
    "adv_champ_test_18_dataset.data    = images\n",
    "adv_champ_test_18_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_champ_test_18_loader = torch.utils.data.DataLoader(adv_champ_test_18_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_0.18/\") if \"test_images_mean\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_0.18/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "images  = images[:,0,:,:]\n",
    "\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_mean_test_18_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_mean_test_18_dataset.data    = None\n",
    "adv_mean_test_18_dataset.targets = None\n",
    "\n",
    "adv_mean_test_18_dataset.data    = images\n",
    "adv_mean_test_18_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_mean_test_18_loader = torch.utils.data.DataLoader(adv_mean_test_18_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_0.50/\") if \"test_images_med\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_0.50/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "images  = images[:,0,:,:]\n",
    "\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_test_50_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_test_50_dataset.data    = None\n",
    "adv_test_50_dataset.targets = None\n",
    "\n",
    "adv_test_50_dataset.data    = images\n",
    "adv_test_50_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_test_50_loader = torch.utils.data.DataLoader(adv_test_50_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_0.50/\") if \"test_images_champ\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_0.50/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "images  = images[:,0,:,:]\n",
    "\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_champ_test_50_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_champ_test_50_dataset.data    = None\n",
    "adv_champ_test_50_dataset.targets = None\n",
    "\n",
    "adv_champ_test_50_dataset.data    = images\n",
    "adv_champ_test_50_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_champ_test_50_loader = torch.utils.data.DataLoader(adv_champ_test_50_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\"mnist_adv_CNN_0.50/\") if \"test_images_mean\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(\"mnist_adv_CNN_0.50/\" + d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images)\n",
    "images  = transform_back(images)\n",
    "images  = images[:,0,:,:]\n",
    "\n",
    "targets = torch.hstack(targets)\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "\n",
    "# Test data loader with batch_size 128\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# AdvTest dataset\n",
    "adv_mean_test_50_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=transform_mnist)\n",
    "adv_mean_test_50_dataset.data    = None\n",
    "adv_mean_test_50_dataset.targets = None\n",
    "\n",
    "adv_mean_test_50_dataset.data    = images\n",
    "adv_mean_test_50_dataset.targets = targets\n",
    "\n",
    "# Test data loader with batch_size 1\n",
    "adv_mean_test_50_loader = torch.utils.data.DataLoader(adv_mean_test_50_dataset, batch_size=128, shuffle=True,\n",
    "                                         generator=torch.Generator().manual_seed(156))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 32, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, loader):\n",
    "    total_correct = 0\n",
    "    for data in loader:\n",
    "        images, labels = data\n",
    "        # images = images.view(-1, 28*28)\n",
    "        y    = model(images)\n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        total_correct += torch.sum(pred==labels).item()\n",
    "    return total_correct / len(loader.dataset.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdvBNN vs BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n"
     ]
    }
   ],
   "source": [
    "sampled_adv_models_50       = load_models(K = 50,modelname=\"models/model-cnn-adv-med0.50.pt\")\n",
    "sampled_adv_models_50_champ = load_models(K = 50,modelname=\"models/model-cnn-adv-champ0.50.pt\")\n",
    "sampled_adv_models_50_mean  = load_models(K = 50,modelname=\"models/model-cnn-adv-mean0.50.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n"
     ]
    }
   ],
   "source": [
    "sampled_adv_models_18       = load_models(K = 50,modelname=\"models/model-cnn-adv-med0.18.pt\")\n",
    "sampled_adv_models_18_champ = load_models(K = 50,modelname=\"models/model-cnn-adv-champ0.18.pt\")\n",
    "sampled_adv_models_18_mean  = load_models(K = 50,modelname=\"models/model-cnn-adv-mean0.18.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n",
      "Loaded 50 sample models\n"
     ]
    }
   ],
   "source": [
    "sampled_adv_models_05       = load_models(K = 50,modelname=\"models/model-cnn-adv-med0.05.pt\")\n",
    "sampled_adv_models_05_champ = load_models(K = 50,modelname=\"models/model-cnn-adv-champ0.05.pt\")\n",
    "sampled_adv_models_05_mean  = load_models(K = 50,modelname=\"models/model-cnn-adv-mean0.05.pt\")\n",
    "\n",
    "sampled_models        = load_models(K = 50,modelname=\"models/model-cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = torch.load(\"models/CNN.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9827"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.901447451227187"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, adv_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.897293895531781"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, adv_champ_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9092511013215859"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, adv_mean_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5607749192792417"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, adv_test_18_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025356576862123614"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, adv_test_50_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.05) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9887\n",
      "mean:  0.9841300000000001 , sd:  0.0027\n",
      "min:   0.9765\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_05]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.05) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9886\n",
      "mean:  0.985552 , sd:  0.003\n",
      "min:   0.9686\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_05_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_mean(eps=0.05) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9903\n",
      "mean:  0.9864219999999999 , sd:  0.0021\n",
      "min:   0.9778\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_05_mean]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=18) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.9889\n",
      "mean:  0.984654 , sd:  0.0036\n",
      "min:  0.9647\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_18]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=18) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.9884\n",
      "mean:  0.98449 , sd:  0.0025\n",
      "min:  0.9777\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_18_champ]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_mean(eps=18) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.9885\n",
      "mean:  0.9850899999999999 , sd:  0.0026\n",
      "min:  0.9771\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_18_mean]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=50) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.9844\n",
      "mean:  0.979686 , sd:  0.003\n",
      "min:  0.9686\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_50]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=50) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.9863\n",
      "mean:  0.9817400000000001 , sd:  0.0028\n",
      "min:  0.9746\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_50_champ]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_mean(eps=50) vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.9882\n",
      "mean:  0.9829079999999999 , sd:  0.003\n",
      "min:  0.9752\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_adv_models_50_mean]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.9824\n",
      "mean:  0.975064 , sd:  0.0083\n",
      "min:  0.938\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, test_loader) for model in sampled_models]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.05) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.9448709880427942\n",
      "mean:  0.925802391441158 , sd:  0.0118\n",
      "min:  0.8974197608558842\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_adv_models_05]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.05) vs Adv Test (Champ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.9422278162366268\n",
      "mean:  0.9207023285084958 , sd:  0.0123\n",
      "min:  0.891881686595343\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_champ_test_loader) for model in  sampled_adv_models_05]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.05) vs AdvTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9553178099433606\n",
      "mean:  0.9404581497797356 , sd:  0.0131\n",
      "min:   0.8658275645059786\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in sampled_adv_models_05_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.18) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9666456891126495\n",
      "mean:  0.958431718061674 , sd:  0.0061\n",
      "min:   0.938703587161737\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_adv_models_18]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.18) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9676526117054751\n",
      "mean:  0.956860918816866 , sd:  0.0072\n",
      "min:   0.9384518565135305\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_adv_models_18_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=50) vs AdvTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.9149150409062303\n",
      "mean:  0.8933593455003145 , sd:  0.0145\n",
      "min:  0.8488357457520453\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in sampled_adv_models_50]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=50) vs AdvTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.917684078036501\n",
      "mean:  0.8943687853996224 , sd:  0.017\n",
      "min:  0.8586532410320956\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in sampled_adv_models_50_champ]\n",
    "print(\"max: \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min: \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN vs. Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.8837004405286344\n",
      "mean:  0.8339332913782251 , sd:  0.0426\n",
      "min:  0.6415355569540592\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_loader) for model in  sampled_models]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.8764002517306482\n",
      "mean:  0.8200956576463185 , sd:  0.0436\n",
      "min:  0.62039018250472\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_champ_test_loader) for model in  sampled_models]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Test (eps=0.18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5607749192792417"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, adv_test_18_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.05) vs Adv Test (eps=0.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.7860639516717008\n",
      "mean:  0.7239787522133111 , sd:  0.0357\n",
      "min:   0.6259764607853349\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_18_loader) for model in  sampled_adv_models_05]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.05) vs AdvTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.8353296531611291\n",
      "mean:  0.7690990521820644 , sd:  0.0488\n",
      "min:   0.5811894594313093\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_18_loader) for model in sampled_adv_models_05_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.18) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9731277991875846\n",
      "mean:  0.961314446411832 , sd:  0.0061\n",
      "min:   0.947817935631705\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_18_loader) for model in  sampled_adv_models_18]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.18) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9737527340901989\n",
      "mean:  0.9638162691386314 , sd:  0.0069\n",
      "min:   0.9361524841162379\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_18_loader) for model in  sampled_adv_models_18_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.50) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.6363920424955734\n",
      "mean:  0.5598500156233726 , sd:  0.0431\n",
      "min:   0.4446411832100823\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_18_loader) for model in  sampled_adv_models_50]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.50) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.695760858243933\n",
      "mean:  0.5993146547234663 , sd:  0.0431\n",
      "min:   0.4961983126757629\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_18_loader) for model in  sampled_adv_models_50_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN vs. Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.4770336423289241\n",
      "mean:  0.3323757941881054 , sd:  0.05\n",
      "min:   0.2345589001145714\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_18_loader) for model in  sampled_models]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.8764002517306482\n",
      "mean:  0.8200956576463185 , sd:  0.0436\n",
      "min:  0.62039018250472\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_champ_test_loader) for model in  sampled_models]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Test (eps=0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025356576862123614"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(cnn_model, adv_test_50_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.05) vs Adv Test (eps=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.05852388498981209\n",
      "mean:  0.044496264432872995 , sd:  0.0063\n",
      "min:   0.03305410912383971\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_50_loader) for model in  sampled_adv_models_05]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.05) vs Adv Test (eps=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.06282544713606521\n",
      "mean:  0.05027620556939099 , sd:  0.0062\n",
      "min:   0.035884084220058864\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_50_loader) for model in  sampled_adv_models_05_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.8353296531611291\n",
      "mean:  0.7690990521820644 , sd:  0.0488\n",
      "min:   0.5811894594313093\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_18_loader) for model in sampled_adv_models_05_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.18) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.22866198777450758\n",
      "mean:  0.12820466379895856 , sd:  0.0327\n",
      "min:   0.08852162100973511\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_50_loader) for model in  sampled_adv_models_18]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.18) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.3239755490151687\n",
      "mean:  0.14503282771111617 , sd:  0.0527\n",
      "min:   0.0775413176364048\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_50_loader) for model in  sampled_adv_models_18_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN(eps=0.50) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9450984831333484\n",
      "mean:  0.9181118406158026 , sd:  0.0137\n",
      "min:   0.8784242698664252\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_50_loader) for model in  sampled_adv_models_50]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdvBNN_champ(eps=0.50) vs Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.9307222096445551\n",
      "mean:  0.9089472492642066 , sd:  0.0188\n",
      "min:   0.8162780167534526\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_50_loader) for model in  sampled_adv_models_50_champ]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN vs. Adv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:   0.05467511885895404\n",
      "mean:  0.027729227982793755 , sd:  0.0094\n",
      "min:   0.010640706361784016\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_test_50_loader) for model in  sampled_models]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.8764002517306482\n",
      "mean:  0.8200956576463185 , sd:  0.0436\n",
      "min:  0.62039018250472\n"
     ]
    }
   ],
   "source": [
    "accs = [evaluate_accuracy(model, adv_champ_test_loader) for model in  sampled_models]\n",
    "print(\"max:  \",max(accs))\n",
    "print(\"mean: \", np.mean(accs), \", sd: \", round(np.std(accs),4))\n",
    "print(\"min:  \",min(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
