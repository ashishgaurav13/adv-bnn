{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import tqdm\n",
    "import os, pickle\n",
    "import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "common.set_seed(156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "    def __init__(self, ni, nh, no):\n",
    "        super(NN, self).__init__()\n",
    "        self.A = torch.nn.Linear(ni, nh)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.B = torch.nn.Linear(nh, no)\n",
    "    def forward(self, x):\n",
    "        # Two layer neural network\n",
    "        x = self.B(self.relu(self.A(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "train_dataset = torchvision.datasets.MNIST('.', train=True, download=True,\n",
    "                       transform=torchvision.transforms.ToTensor())\n",
    "# Train data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "# Point estimate NN\n",
    "net = NN(28*28, 1024, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, y):\n",
    "    # Put priors on weights and biases \n",
    "    priors = {\n",
    "        \"A.weight\": pyro.distributions.Normal(\n",
    "            loc=torch.zeros_like(net.A.weight), \n",
    "            scale=torch.ones_like(net.A.weight),\n",
    "        ).independent(2),\n",
    "        \"A.bias\": pyro.distributions.Normal(\n",
    "            loc=torch.zeros_like(net.A.bias), \n",
    "            scale=torch.ones_like(net.A.bias),\n",
    "        ).independent(1),\n",
    "        \"B.weight\": pyro.distributions.Normal(\n",
    "            loc=torch.zeros_like(net.B.weight), \n",
    "            scale=torch.ones_like(net.B.weight),\n",
    "        ).independent(2),\n",
    "        \"B.bias\": pyro.distributions.Normal(\n",
    "            loc=torch.zeros_like(net.B.bias), \n",
    "            scale=torch.ones_like(net.B.bias),\n",
    "        ).independent(1),\n",
    "    }\n",
    "    # Create a NN module using the priors\n",
    "    lmodule = pyro.random_module(\"module\", net, priors)\n",
    "    regressor = lmodule()\n",
    "    # Do a forward pass on the NN module, i.e. yhat=f(x) and condition on yhat=y\n",
    "    lhat = torch.nn.LogSoftmax(dim=1)(regressor(x))\n",
    "    pyro.sample(\"obs\", pyro.distributions.Categorical(logits=lhat).independent(1), obs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "softplus = torch.nn.Softplus()\n",
    "def guide(x, y):\n",
    "    # Create parameters for variational distribution priors\n",
    "    Aw_mu = pyro.param(\"Aw_mu\", torch.randn_like(net.A.weight))\n",
    "    Aw_sigma = softplus(pyro.param(\"Aw_sigma\", torch.randn_like(net.A.weight)))\n",
    "    Ab_mu = pyro.param(\"Ab_mu\", torch.randn_like(net.A.bias))\n",
    "    Ab_sigma = softplus(pyro.param(\"Ab_sigma\", torch.randn_like(net.A.bias)))\n",
    "    Bw_mu = pyro.param(\"Bw_mu\", torch.randn_like(net.B.weight))\n",
    "    Bw_sigma = softplus(pyro.param(\"Bw_sigma\", torch.randn_like(net.B.weight)))\n",
    "    Bb_mu = pyro.param(\"Bb_mu\", torch.randn_like(net.B.bias))\n",
    "    Bb_sigma = softplus(pyro.param(\"Bb_sigma\", torch.randn_like(net.B.bias)))\n",
    "    # Create random variables similarly to model\n",
    "    priors = {\n",
    "        \"A.weight\": pyro.distributions.Normal(loc=Aw_mu, scale=Aw_sigma).independent(2),\n",
    "        \"A.bias\": pyro.distributions.Normal(loc=Ab_mu, scale=Ab_sigma).independent(1),\n",
    "        \"B.weight\": pyro.distributions.Normal(loc=Bw_mu, scale=Bw_sigma).independent(2),\n",
    "        \"B.bias\": pyro.distributions.Normal(loc=Bb_mu, scale=Bb_sigma).independent(1),\n",
    "    }\n",
    "    # Return NN module from these random variables\n",
    "    lmodule = pyro.random_module(\"module\", net, priors)\n",
    "    return lmodule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do stochastic variational inference to find q(w) closest to p(w|D)\n",
    "svi = pyro.infer.SVI(\n",
    "    model, guide, pyro.optim.Adam({'lr': 0.01}), pyro.infer.Trace_ELBO(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_models(epochs = 10, K = 100, modelname = \"model.pt\"):\n",
    "    if os.path.exists(modelname):\n",
    "        print(\"File exists\")\n",
    "        return\n",
    "    # Train with SVI\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0.\n",
    "        for data in train_loader:\n",
    "            images, labels = data\n",
    "            images = images.view(-1, 28*28)\n",
    "            loss += svi.step(images, labels)\n",
    "        loss /= len(train_loader.dataset)\n",
    "        print(\"Epoch %g: Loss = %g\" % (epoch, loss))\n",
    "    # Sample k models from the posterior\n",
    "    sampled_models = [guide(None, None) for i in range(K)]\n",
    "    # Save the models\n",
    "    nn_dicts = []\n",
    "    for i in range(len(sampled_models)):\n",
    "        nn_dicts += [sampled_models[i].state_dict()]\n",
    "    torch.save(nn_dicts, modelname)\n",
    "    print(\"Saved %d models\" % K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(K = 100):\n",
    "    # Load the models\n",
    "    sampled_models = [NN(28*28, 1024, 10) for i in range(K)]\n",
    "    for net, state_dict in zip(sampled_models, torch.load(\"model.pt\")):\n",
    "        net.load_state_dict(state_dict)\n",
    "    print(\"Loaded %d sample models\" % K)\n",
    "    return sampled_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_and_save_models(epochs = 10, K = 100, modelname = \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25 sample models\n"
     ]
    }
   ],
   "source": [
    "sampled_models = load_models(K = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Adversarial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(model, images, loss_target = None):\n",
    "    output = model(images)\n",
    "    output = torch.nn.LogSoftmax(dim=-1)(output)\n",
    "    which_class = torch.argmax(output).item()\n",
    "    if loss_target:\n",
    "        loss, target = loss_target\n",
    "        loss(output, target).backward()\n",
    "    return which_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def otcm(images, eps, saliency):\n",
    "    return torch.clamp(images.clone()-eps*saliency, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many models can an adversarial example fool?\n",
    "def how_many_can_it_fool(sampled_models, eps, saliency,images):\n",
    "    fool = 0\n",
    "    for k in range(len(sampled_models)):\n",
    "        # Forward pass on sampled model k\n",
    "        old_class = forward_pass(sampled_models[k], images)\n",
    "        # One step Target Class Method (OTCM); saliency is noise\n",
    "        new_images = otcm(images, eps, saliency)\n",
    "        # Forward pass again on adv. example\n",
    "        new_class = forward_pass(sampled_models[k], new_images)\n",
    "        # If we change the class, we fool the model\n",
    "        fool += int(old_class != new_class)\n",
    "    return fool/len(sampled_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_saliency(EPS,target,images):\n",
    "    # Collect noises (saliencies)\n",
    "    # EPS = 0.18\n",
    "    saliencies = []\n",
    "    how_many_fooled = []\n",
    "    torch.set_printoptions(sci_mode=False)\n",
    "    # target = torch.tensor([1])\n",
    "    target = torch.tensor([target])\n",
    "    for k in range(len(sampled_models)):\n",
    "        # Forward pass\n",
    "        # Compute loss w.r.t. an incorrect class\n",
    "        # Note that we just have to ensure this class is different from targets\n",
    "        # print(\"\\r Processing \" + str(k+1) + \"/%s\" % len(sampled_models), end=\"\")\n",
    "        images.grad = None\n",
    "        images.requires_grad = True\n",
    "        old_class = forward_pass(sampled_models[k], images, [torch.nn.NLLLoss(), target])\n",
    "        # Compute adversarial example\n",
    "        new_images = otcm(images, EPS, images.grad.sign())\n",
    "        # Forward pass on adv. example\n",
    "        new_class = forward_pass(sampled_models[k], new_images)\n",
    "        if old_class != new_class:\n",
    "            # How many models can this adv. example fool?\n",
    "            how_many_fooled += [how_many_can_it_fool(sampled_models, EPS, images.grad.sign(), images)]\n",
    "            saliencies += [images.grad.sign().view(28, 28)]\n",
    "    # print(\"\\nFinished\")\n",
    "    return saliencies, how_many_fooled\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_saliencies(saliencies,success):\n",
    "    # distributional saliency map\n",
    "    saliencies = torch.stack(saliencies)\n",
    "    # print(saliencies.shape)\n",
    "    combined_med  = torch.zeros(28, 28)\n",
    "    combined_mean = torch.zeros(28, 28)\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            # choose median perturbation\n",
    "            combined_med[i, j] = np.percentile(saliencies[:, i, j].numpy(), 50)\n",
    "            combined_mean[i, j] = saliencies[:, i, j].mean().item()\n",
    "    combined_med  = combined_med.flatten()\n",
    "    combined_mean = combined_mean.flatten()\n",
    "    champ         = saliencies[success.index(max(success))].flatten()\n",
    "    return combined_med, combined_mean, champ\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training BNN with Adversarial Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate Train with Saliency Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "train_dataset = torchvision.datasets.MNIST('.', train=True, download=True,\n",
    "                       transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                       transform=torchvision.transforms.ToTensor())\n",
    "# Test data loader with batch_size 1\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(\".\") if \"images_champ\" in d]\n",
    "\n",
    "images  = []\n",
    "targets = []\n",
    "for d in dirs:\n",
    "    with open(d, 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        images.append(temp[\"images\"])\n",
    "        targets.append(temp[\"labels\"])\n",
    "        \n",
    "images  = torch.vstack(images).int()\n",
    "targets = torch.hstack(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.data    = torch.vstack([train_dataset.data, images])\n",
    "train_dataset.targets = torch.hstack([train_dataset.targets, targets])\n",
    "\n",
    "train, val = random_split(train_dataset,[51024,10000], generator=torch.Generator().manual_seed(156))\n",
    "\n",
    "# Train data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True)\n",
    "val_loader   = torch.utils.data.DataLoader(val  , batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adversarial(epochs = 10, K = 100, modelname = \"AdvBNN_champ.pt\"):\n",
    "    if os.path.exists(modelname):\n",
    "        print(\"File exists\")\n",
    "        return\n",
    "    # Train with SVI\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0.\n",
    "        for data in train_loader:\n",
    "            images, labels = data\n",
    "            images = images.view(-1, 28*28)\n",
    "            loss  += svi.step(images, labels)\n",
    "        loss /= len(train_loader.dataset)\n",
    "        # model.eval()     # Optional when not using Model Specific layer\n",
    "        val_loss = 0.\n",
    "        for data in val_loader:\n",
    "            images, labels = data\n",
    "            images = images.view(-1, 28*28)\n",
    "            val_loss += svi.evaluate_loss(images, labels)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        print(\"Epoch %g: Loss = %g: Val_Loss = %g\" % (epoch, loss,val_loss))\n",
    "    # Sample k models from the posterior\n",
    "    sampled_models = [guide(None, None) for i in range(K)]\n",
    "    # Save the models\n",
    "    nn_dicts = []\n",
    "    for i in range(len(sampled_models)):\n",
    "        nn_dicts += [sampled_models[i].state_dict()]\n",
    "    torch.save(nn_dicts, modelname)\n",
    "    print(\"Saved %d models\" % K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1485.75: Val_Loss = 293.375\n",
      "Epoch 1: Loss = 196.763: Val_Loss = 143.19\n",
      "Epoch 2: Loss = 118.251: Val_Loss = 100.868\n",
      "Epoch 3: Loss = 90.1813: Val_Loss = 82.1258\n",
      "Epoch 4: Loss = 76.7518: Val_Loss = 73.7922\n",
      "Epoch 5: Loss = 70.8402: Val_Loss = 69.6865\n",
      "Epoch 6: Loss = 68.1185: Val_Loss = 68.456\n",
      "Epoch 7: Loss = 66.6583: Val_Loss = 66.7859\n",
      "Epoch 8: Loss = 66.1654: Val_Loss = 65.5855\n",
      "Epoch 9: Loss = 65.7248: Val_Loss = 66.2054\n",
      "Saved 100 models\n"
     ]
    }
   ],
   "source": [
    "train_adversarial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
